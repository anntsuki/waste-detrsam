INFO 2025-06-30 15:53:51,918 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 15:53:51,919 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 15:53:51,919 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=42053
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 15:53:51,920 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 15:53:51,922 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 15:53:52,610 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 15:53:52,613 trainer.py:1059: ====================
INFO 2025-06-30 15:53:52,614 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 15:53:52,615 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 15:53:52,618 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 15:53:52,619 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 15:53:52,619 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 15:53:52,619 trainer.py:1069: ====================
INFO 2025-06-30 15:56:13,208 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 15:56:13,210 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 15:56:13,210 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=11658
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 15:56:13,211 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 15:56:13,211 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 15:56:13,774 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 15:56:13,777 trainer.py:1059: ====================
INFO 2025-06-30 15:56:13,778 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 15:56:13,779 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 15:56:13,782 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 15:56:13,782 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 15:56:13,783 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 15:56:13,783 trainer.py:1069: ====================
INFO 2025-06-30 15:58:01,296 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 15:58:01,296 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 15:58:01,296 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=59560
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 15:58:01,297 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 15:58:01,298 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 15:58:01,826 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 15:58:01,828 trainer.py:1059: ====================
INFO 2025-06-30 15:58:01,828 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 15:58:01,831 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 15:58:01,834 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 15:58:01,834 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 15:58:01,834 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 15:58:01,834 trainer.py:1069: ====================
INFO 2025-06-30 16:00:45,517 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:00:45,518 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:00:45,518 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=12256
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:00:45,519 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:00:45,520 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:00:46,055 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:00:46,057 trainer.py:1059: ====================
INFO 2025-06-30 16:00:46,058 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:00:46,060 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:00:46,062 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:00:46,063 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:00:46,063 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:00:46,063 trainer.py:1069: ====================
INFO 2025-06-30 16:01:54,345 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:01:54,345 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:01:54,346 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=59829
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:01:54,346 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:01:54,347 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:01:54,973 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:01:54,975 trainer.py:1059: ====================
INFO 2025-06-30 16:01:54,975 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:01:54,977 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:01:54,980 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:01:54,980 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:01:54,980 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:01:54,980 trainer.py:1069: ====================
INFO 2025-06-30 16:04:30,729 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:04:30,730 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:04:30,730 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=57407
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:04:30,731 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:04:30,732 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:04:31,313 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:04:31,315 trainer.py:1059: ====================
INFO 2025-06-30 16:04:31,315 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:04:31,318 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:04:31,321 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:04:31,321 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:04:31,321 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:04:31,321 trainer.py:1069: ====================
INFO 2025-06-30 16:04:31,324 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:04:31,324 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:04:31,431 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:04:31,431 finetune_trainer.py:  27: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:04:31,431 finetune_trainer.py:  30: Freezing Image Encoder...
INFO 2025-06-30 16:04:31,434 finetune_trainer.py:  37: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:05:42,895 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:05:42,899 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:05:42,899 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=62383
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:05:42,900 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:05:42,901 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:05:43,590 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:05:43,593 trainer.py:1059: ====================
INFO 2025-06-30 16:05:43,594 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:05:43,597 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:05:43,600 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:05:43,601 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:05:43,601 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:05:43,601 trainer.py:1069: ====================
INFO 2025-06-30 16:05:43,604 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:05:43,605 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:05:43,688 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:05:43,688 finetune_trainer.py:  21: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:05:43,689 finetune_trainer.py:  27: Freezing Image Encoder...
INFO 2025-06-30 16:05:43,691 finetune_trainer.py:  33: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:05:43,691 finetune_trainer.py:  37: Enabling training for Mask Decoder...
INFO 2025-06-30 16:05:43,693 finetune_trainer.py:  48: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:06:33,395 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:06:33,395 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:06:33,395 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=59034
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:06:33,397 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:06:33,398 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:06:33,974 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:06:33,977 trainer.py:1059: ====================
INFO 2025-06-30 16:06:33,977 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:06:33,978 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:06:33,981 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:06:33,982 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:06:33,982 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:06:33,982 trainer.py:1069: ====================
INFO 2025-06-30 16:06:33,986 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:06:33,987 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:06:34,071 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:06:34,072 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:06:34,072 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:06:34,073 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:06:34,073 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:06:34,075 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:08:29,769 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:08:29,770 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:08:29,771 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=36641
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:08:29,772 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:08:29,773 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:08:30,350 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:08:30,353 trainer.py:1059: ====================
INFO 2025-06-30 16:08:30,353 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:08:30,355 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:08:30,357 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:08:30,358 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:08:30,358 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:08:30,358 trainer.py:1069: ====================
INFO 2025-06-30 16:08:30,361 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:08:30,361 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:08:30,461 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:08:30,461 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:08:30,461 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:08:30,462 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:08:30,462 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:08:30,464 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:09:35,375 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:09:35,376 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:09:35,376 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=21494
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:09:35,377 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:09:35,378 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:09:35,981 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:09:35,983 trainer.py:1059: ====================
INFO 2025-06-30 16:09:35,984 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:09:35,985 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:09:35,991 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:09:35,991 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:09:35,991 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:09:35,991 trainer.py:1069: ====================
INFO 2025-06-30 16:09:35,994 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:09:35,994 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:09:36,083 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:09:36,083 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:09:36,083 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:09:36,084 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:09:36,084 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:09:36,087 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:09:36,097 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:09:36,823 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:13:32,401 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:13:32,402 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:13:32,402 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=39970
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:13:32,403 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:13:32,404 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:13:32,975 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:13:32,977 trainer.py:1059: ====================
INFO 2025-06-30 16:13:32,977 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:13:32,979 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:13:32,983 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:13:32,983 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:13:32,983 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:13:32,983 trainer.py:1069: ====================
INFO 2025-06-30 16:13:32,986 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:13:32,987 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:13:33,078 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:13:33,079 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:13:33,079 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:13:33,079 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:13:33,080 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:13:33,082 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:13:33,094 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:13:33,549 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:13:33,996 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_large.pt', 'ckpt_state_dict_keys': ['model']}}
INFO 2025-06-30 16:19:57,671 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:19:57,672 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:19:57,672 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=15439
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:19:57,673 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:19:57,673 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:19:58,251 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:19:58,253 trainer.py:1059: ====================
INFO 2025-06-30 16:19:58,253 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:19:58,255 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:19:58,257 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:19:58,258 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:19:58,258 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:19:58,258 trainer.py:1069: ====================
INFO 2025-06-30 16:19:58,261 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:19:58,261 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:19:58,348 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:19:58,348 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:19:58,348 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:19:58,349 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:19:58,349 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:19:58,351 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:19:58,362 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:19:58,804 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:20:55,361 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:20:55,362 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:20:55,362 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=41194
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:20:55,364 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:20:55,364 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:20:55,913 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:20:55,915 trainer.py:1059: ====================
INFO 2025-06-30 16:20:55,916 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:20:55,917 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:20:55,920 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:20:55,920 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:20:55,920 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:20:55,920 trainer.py:1069: ====================
INFO 2025-06-30 16:20:55,923 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:20:55,924 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:20:56,005 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:20:56,005 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:20:56,005 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:20:56,006 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:20:56,006 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:20:56,008 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:20:56,019 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:20:56,469 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:20:56,586 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
ERROR 2025-06-30 16:21:21,671 sam2_datasets.py:  63: Caught UnboundLocalError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\utils.py", line 104, in __getitem__
    return self.dataset[self.epoch_ids[idx]]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\dataset.py", line 302, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 132, in __getitem__
    return self._get_datapoint(idx)
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 74, in _get_datapoint
    datapoint = self.construct(video, sampled_frms_and_objs, segment_loader)
UnboundLocalError: local variable 'video' referenced before assignment

INFO 2025-06-30 16:23:18,282 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:23:18,283 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:23:18,283 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=52948
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:23:18,284 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:23:18,285 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:23:18,801 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:23:18,804 trainer.py:1059: ====================
INFO 2025-06-30 16:23:18,804 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:23:18,807 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:23:18,810 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:23:18,810 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:23:18,810 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:23:18,810 trainer.py:1069: ====================
INFO 2025-06-30 16:23:18,814 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:23:18,815 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:23:18,902 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:23:18,902 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:23:18,902 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:23:18,903 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:23:18,904 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:23:18,906 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:23:18,919 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:23:19,346 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:23:19,497 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
ERROR 2025-06-30 16:23:25,973 sam2_datasets.py:  63: Caught UnboundLocalError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\utils.py", line 104, in __getitem__
    return self.dataset[self.epoch_ids[idx]]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\dataset.py", line 302, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 132, in __getitem__
    return self._get_datapoint(idx)
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 74, in _get_datapoint
    datapoint = self.construct(video, sampled_frms_and_objs, segment_loader)
UnboundLocalError: local variable 'video' referenced before assignment

INFO 2025-06-30 16:24:22,356 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:24:22,357 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:24:22,357 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=58516
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:24:22,358 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:24:22,360 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:24:22,880 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:24:22,883 trainer.py:1059: ====================
INFO 2025-06-30 16:24:22,883 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:24:22,885 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:24:22,888 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:24:22,888 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:24:22,888 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:24:22,888 trainer.py:1069: ====================
INFO 2025-06-30 16:24:22,891 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:24:22,891 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:24:22,976 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:24:22,976 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:24:22,976 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:24:22,976 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:24:22,978 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:24:22,979 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:24:22,990 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:24:23,450 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:24:23,547 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
ERROR 2025-06-30 16:24:30,155 sam2_datasets.py:  63: Caught UnboundLocalError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\utils.py", line 104, in __getitem__
    return self.dataset[self.epoch_ids[idx]]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\dataset.py", line 302, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 132, in __getitem__
    return self._get_datapoint(idx)
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 74, in _get_datapoint
    datapoint = self.construct(video, sampled_frms_and_objs, segment_loader)
UnboundLocalError: local variable 'video' referenced before assignment

INFO 2025-06-30 16:24:57,451 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:24:57,451 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:24:57,452 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=48436
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:24:57,452 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:24:57,453 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:24:57,954 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:24:57,957 trainer.py:1059: ====================
INFO 2025-06-30 16:24:57,957 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:24:57,960 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:24:57,963 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:24:57,963 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:24:57,963 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:24:57,964 trainer.py:1069: ====================
INFO 2025-06-30 16:24:57,967 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:24:57,967 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:24:58,048 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:24:58,049 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:24:58,049 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:24:58,050 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:24:58,050 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:24:58,052 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:24:58,063 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:24:58,493 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:24:58,591 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
ERROR 2025-06-30 16:25:05,380 sam2_datasets.py:  63: Caught UnboundLocalError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\utils.py", line 104, in __getitem__
    return self.dataset[self.epoch_ids[idx]]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\dataset.py", line 302, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 132, in __getitem__
    return self._get_datapoint(idx)
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 74, in _get_datapoint
    datapoint = self.construct(video, sampled_frms_and_objs, segment_loader)
UnboundLocalError: local variable 'video' referenced before assignment

INFO 2025-06-30 16:28:06,374 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:28:06,375 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:28:06,376 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=45702
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:28:06,377 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:28:06,377 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:28:06,892 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:28:06,894 trainer.py:1059: ====================
INFO 2025-06-30 16:28:06,894 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:28:06,897 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:28:06,900 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:28:06,900 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:28:06,900 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:28:06,900 trainer.py:1069: ====================
INFO 2025-06-30 16:28:06,903 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:28:06,903 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:28:06,985 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:28:06,986 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:28:06,986 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:28:06,987 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:28:06,987 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:28:06,989 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:28:07,000 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:28:07,447 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:28:07,539 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
ERROR 2025-06-30 16:28:14,086 sam2_datasets.py:  63: Caught UnboundLocalError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\utils.py", line 104, in __getitem__
    return self.dataset[self.epoch_ids[idx]]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\dataset.py", line 302, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 132, in __getitem__
    return self._get_datapoint(idx)
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 74, in _get_datapoint
    datapoint = self.construct(video, sampled_frms_and_objs, segment_loader)
UnboundLocalError: local variable 'video' referenced before assignment

INFO 2025-06-30 16:39:15,899 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:39:15,899 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:39:15,899 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=32724
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:39:15,900 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:39:15,902 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:39:16,430 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:39:16,434 trainer.py:1059: ====================
INFO 2025-06-30 16:39:16,434 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:39:16,435 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:39:16,438 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:39:16,438 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:39:16,438 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:39:16,438 trainer.py:1069: ====================
INFO 2025-06-30 16:39:16,441 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:39:16,441 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:39:16,542 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:39:16,543 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:39:16,543 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:39:16,544 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:39:16,544 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:39:16,546 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:39:16,558 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:45:34,603 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:45:34,605 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:45:34,605 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=19762
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:45:34,606 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:45:34,607 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:45:35,117 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:45:35,120 trainer.py:1059: ====================
INFO 2025-06-30 16:45:35,120 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:45:35,123 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:45:35,125 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:45:35,125 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:45:35,126 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:45:35,126 trainer.py:1069: ====================
INFO 2025-06-30 16:45:35,128 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:45:35,129 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:45:35,209 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:45:35,209 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:45:35,209 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:45:35,210 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:45:35,210 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:45:35,212 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:45:35,224 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:46:16,897 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:46:16,898 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:46:16,899 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=21776
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:46:16,900 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:46:16,901 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:46:17,403 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:46:17,406 trainer.py:1059: ====================
INFO 2025-06-30 16:46:17,407 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:46:17,408 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:46:17,411 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:46:17,411 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:46:17,411 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:46:17,411 trainer.py:1069: ====================
INFO 2025-06-30 16:46:17,415 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:46:17,415 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:46:17,500 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:46:17,500 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:46:17,501 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:46:17,501 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:46:17,501 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:46:17,503 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:46:17,514 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:47:00,123 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:47:00,124 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:47:00,124 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=18204
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:47:00,125 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:47:00,125 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:47:00,633 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:47:00,636 trainer.py:1059: ====================
INFO 2025-06-30 16:47:00,636 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:47:00,638 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:47:00,640 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:47:00,641 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:47:00,641 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:47:00,641 trainer.py:1069: ====================
INFO 2025-06-30 16:47:00,644 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:47:00,644 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:47:00,728 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:47:00,728 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:47:00,728 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:47:00,729 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:47:00,729 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:47:00,731 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:47:00,743 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:47:58,408 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:47:58,409 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:47:58,409 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=60456
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:47:58,410 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:47:58,412 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:47:58,921 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:47:58,923 trainer.py:1059: ====================
INFO 2025-06-30 16:47:58,924 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:47:58,926 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:47:58,929 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:47:58,929 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:47:58,929 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:47:58,930 trainer.py:1069: ====================
INFO 2025-06-30 16:47:58,932 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:47:58,932 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:47:59,016 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:47:59,016 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:47:59,016 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:47:59,018 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:47:59,018 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:47:59,020 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:47:59,030 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:47:59,461 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:47:59,568 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
ERROR 2025-06-30 16:48:07,077 sam2_datasets.py:  63: Caught UnboundLocalError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 132, in __getitem__
    return self._get_datapoint(idx)
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 74, in _get_datapoint
    datapoint = self.construct(video, sampled_frms_and_objs, segment_loader)
UnboundLocalError: local variable 'video' referenced before assignment

INFO 2025-06-30 16:48:56,058 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:48:56,058 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:48:56,058 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=48610
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:48:56,060 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:48:56,061 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:48:56,573 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:48:56,575 trainer.py:1059: ====================
INFO 2025-06-30 16:48:56,575 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:48:56,577 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:48:56,580 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:48:56,580 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:48:56,580 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:48:56,581 trainer.py:1069: ====================
INFO 2025-06-30 16:48:56,584 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:48:56,584 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:48:56,666 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:48:56,667 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:48:56,667 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:48:56,669 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:48:56,669 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:48:56,671 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:48:56,683 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:48:57,114 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:48:57,257 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
ERROR 2025-06-30 16:49:03,945 sam2_datasets.py:  63: Caught UnboundLocalError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 132, in __getitem__
    return self._get_datapoint(idx)
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 74, in _get_datapoint
    datapoint = self.construct(video, sampled_frms_and_objs, segment_loader)
UnboundLocalError: local variable 'video' referenced before assignment

INFO 2025-06-30 16:54:54,366 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:54:54,367 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:54:54,367 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=42219
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:54:54,368 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:54:54,369 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:54:54,873 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:54:54,876 trainer.py:1059: ====================
INFO 2025-06-30 16:54:54,877 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:54:54,878 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:54:54,881 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:54:54,881 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:54:54,881 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:54:54,882 trainer.py:1069: ====================
INFO 2025-06-30 16:54:54,884 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:54:54,884 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:54:54,968 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:54:54,968 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:54:54,968 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:54:54,969 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:54:54,969 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:54:54,972 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:54:54,983 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:54:55,418 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:54:55,521 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
ERROR 2025-06-30 16:55:01,939 sam2_datasets.py:  63: Caught UnboundLocalError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 132, in __getitem__
    return self._get_datapoint(idx)
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 74, in _get_datapoint
    datapoint = self.construct(video, sampled_frms_and_objs, segment_loader)
UnboundLocalError: local variable 'video' referenced before assignment

INFO 2025-06-30 16:56:21,678 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 16:56:21,678 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 16:56:21,679 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=12980
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 16:56:21,680 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:56:21,681 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 16:56:22,185 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 16:56:22,187 trainer.py:1059: ====================
INFO 2025-06-30 16:56:22,187 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 16:56:22,189 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 16:56:22,191 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 16:56:22,191 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 16:56:22,191 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 16:56:22,192 trainer.py:1069: ====================
INFO 2025-06-30 16:56:22,195 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 16:56:22,195 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:56:22,281 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 16:56:22,281 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 16:56:22,282 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 16:56:22,282 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 16:56:22,283 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 16:56:22,285 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 16:56:22,296 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 16:56:22,729 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 16:56:22,853 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
ERROR 2025-06-30 16:56:32,724 sam2_datasets.py:  63: Caught UnboundLocalError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 132, in __getitem__
    return self._get_datapoint(idx)
  File "E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\training\dataset\vos_dataset.py", line 74, in _get_datapoint
    datapoint = self.construct(video, sampled_frms_and_objs, segment_loader)
UnboundLocalError: local variable 'video' referenced before assignment

INFO 2025-06-30 17:10:53,403 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 17:10:53,405 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 17:10:53,405 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=42252
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 17:10:53,406 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 17:10:53,407 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 17:10:54,031 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 17:10:54,035 trainer.py:1059: ====================
INFO 2025-06-30 17:10:54,035 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 17:10:54,037 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 17:10:54,040 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 17:10:54,040 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 17:10:54,040 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 17:10:54,040 trainer.py:1069: ====================
INFO 2025-06-30 17:10:54,044 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 17:10:54,044 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 17:10:54,126 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 17:10:54,126 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 17:10:54,127 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 17:10:54,127 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 17:10:54,128 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 17:10:54,130 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 17:10:54,144 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 17:10:54,650 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 17:10:54,830 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
INFO 2025-06-30 17:13:42,609 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 17:13:42,609 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 17:13:42,610 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=62215
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 17:13:42,611 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 17:13:42,611 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 17:13:43,207 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 17:13:43,208 trainer.py:1059: ====================
INFO 2025-06-30 17:13:43,210 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 17:13:43,211 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 17:13:43,214 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 17:13:43,214 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 17:13:43,214 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 17:13:43,214 trainer.py:1069: ====================
INFO 2025-06-30 17:13:43,218 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 17:13:43,219 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 17:13:43,310 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 17:13:43,311 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 17:13:43,311 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 17:13:43,312 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 17:13:43,312 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 17:13:43,314 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 17:13:43,330 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 17:13:43,947 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 17:13:44,111 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
INFO 2025-06-30 17:14:05,772 train_utils.py: 271: Train Epoch: [0][  0/100] | Batch Time: 21.44 (21.44) | Data Time: 13.95 (13.95) | Mem (GB): 3.00 (3.00/3.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.51e+00 (1.51e+00)
INFO 2025-06-30 17:14:12,302 train_utils.py: 271: Train Epoch: [0][ 10/100] | Batch Time: 0.59 (2.54) | Data Time: 0.00 (1.27) | Mem (GB): 4.00 (3.91/4.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 2.55e+00 (1.99e+00)
INFO 2025-06-30 17:14:19,135 train_utils.py: 271: Train Epoch: [0][ 20/100] | Batch Time: 0.57 (1.66) | Data Time: 0.00 (0.67) | Mem (GB): 4.00 (3.95/4.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 4.12e+00 (1.80e+00)
INFO 2025-06-30 17:14:25,973 train_utils.py: 271: Train Epoch: [0][ 30/100] | Batch Time: 0.65 (1.34) | Data Time: 0.00 (0.45) | Mem (GB): 4.00 (3.97/4.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 2.32e+00 (1.80e+00)
INFO 2025-06-30 17:14:32,266 train_utils.py: 271: Train Epoch: [0][ 40/100] | Batch Time: 0.60 (1.17) | Data Time: 0.00 (0.34) | Mem (GB): 4.00 (3.98/4.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.31e+00 (1.68e+00)
INFO 2025-06-30 17:14:38,200 train_utils.py: 271: Train Epoch: [0][ 50/100] | Batch Time: 0.61 (1.06) | Data Time: 0.00 (0.28) | Mem (GB): 4.00 (3.98/4.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.89e+00 (1.66e+00)
INFO 2025-06-30 17:14:44,447 train_utils.py: 271: Train Epoch: [0][ 60/100] | Batch Time: 0.52 (0.99) | Data Time: 0.00 (0.23) | Mem (GB): 4.00 (3.98/4.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 2.20e+00 (1.61e+00)
INFO 2025-06-30 17:14:50,640 train_utils.py: 271: Train Epoch: [0][ 70/100] | Batch Time: 0.58 (0.93) | Data Time: 0.00 (0.20) | Mem (GB): 4.00 (3.99/4.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 2.71e+00 (1.67e+00)
INFO 2025-06-30 17:14:56,564 train_utils.py: 271: Train Epoch: [0][ 80/100] | Batch Time: 0.59 (0.89) | Data Time: 0.00 (0.17) | Mem (GB): 4.00 (3.99/4.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 6.91e-01 (1.62e+00)
INFO 2025-06-30 17:15:00,616 train_utils.py: 271: Train Epoch: [0][ 90/100] | Batch Time: 0.39 (0.84) | Data Time: 0.00 (0.15) | Mem (GB): 4.00 (3.99/4.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 5.62e-01 (1.64e+00)
INFO 2025-06-30 17:15:05,628 trainer.py: 950: Estimated time remaining: 00d 00h 51m
INFO 2025-06-30 17:15:05,628 trainer.py: 892: Synchronizing meters
INFO 2025-06-30 17:15:05,629 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.6123426280915738, 'Losses/train_all_loss_mask': 0.01801716483430937, 'Losses/train_all_loss_dice': 0.766203572973609, 'Losses/train_all_loss_iou': 0.48579566087573767, 'Losses/train_all_loss_class': 1.0172512830308733e-07, 'Losses/train_all_core_loss': 1.6123426280915738, 'Trainer/where': 0.02475, 'Trainer/epoch': 0, 'Trainer/steps_train': 100}
INFO 2025-06-30 17:15:25,367 train_utils.py: 271: Train Epoch: [1][  0/100] | Batch Time: 18.68 (18.68) | Data Time: 17.76 (17.76) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 1.35e+00 (1.35e+00)
INFO 2025-06-30 17:15:35,570 train_utils.py: 271: Train Epoch: [1][ 10/100] | Batch Time: 1.06 (2.63) | Data Time: 0.00 (1.68) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 1.81e+00 (1.89e+00)
INFO 2025-06-30 17:15:43,451 train_utils.py: 271: Train Epoch: [1][ 20/100] | Batch Time: 0.88 (1.75) | Data Time: 0.00 (0.88) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 7.14e-01 (1.42e+00)
INFO 2025-06-30 17:15:50,043 train_utils.py: 271: Train Epoch: [1][ 30/100] | Batch Time: 0.62 (1.40) | Data Time: 0.00 (0.60) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 1.34e+00 (1.46e+00)
INFO 2025-06-30 17:16:00,919 train_utils.py: 271: Train Epoch: [1][ 40/100] | Batch Time: 2.79 (1.32) | Data Time: 0.00 (0.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 1.90e+00 (1.41e+00)
INFO 2025-06-30 17:16:09,581 train_utils.py: 271: Train Epoch: [1][ 50/100] | Batch Time: 0.72 (1.23) | Data Time: 0.00 (0.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 2.00e+00 (1.44e+00)
INFO 2025-06-30 17:16:18,518 train_utils.py: 271: Train Epoch: [1][ 60/100] | Batch Time: 0.94 (1.18) | Data Time: 0.00 (0.30) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 7.34e-01 (1.37e+00)
INFO 2025-06-30 17:16:27,105 train_utils.py: 271: Train Epoch: [1][ 70/100] | Batch Time: 0.89 (1.13) | Data Time: 0.00 (0.26) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 1.75e+00 (1.39e+00)
INFO 2025-06-30 17:16:35,426 train_utils.py: 271: Train Epoch: [1][ 80/100] | Batch Time: 0.63 (1.10) | Data Time: 0.00 (0.23) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 5.38e-01 (1.34e+00)
INFO 2025-06-30 17:16:40,012 train_utils.py: 271: Train Epoch: [1][ 90/100] | Batch Time: 0.42 (1.03) | Data Time: 0.00 (0.20) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 5.54e-01 (1.29e+00)
INFO 2025-06-30 17:16:45,116 trainer.py: 950: Estimated time remaining: 00d 01h 01m
INFO 2025-06-30 17:16:45,117 trainer.py: 892: Synchronizing meters
INFO 2025-06-30 17:16:45,117 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.3149421408772468, 'Losses/train_all_loss_mask': 0.013827893463894726, 'Losses/train_all_loss_dice': 0.6422437993437051, 'Losses/train_all_loss_iou': 0.39614017710089683, 'Losses/train_all_loss_class': 3.0278873019540243e-07, 'Losses/train_all_core_loss': 1.3149421408772468, 'Trainer/where': 0.04975, 'Trainer/epoch': 1, 'Trainer/steps_train': 200}
INFO 2025-06-30 17:17:13,225 train_utils.py: 271: Train Epoch: [2][  0/100] | Batch Time: 27.05 (27.05) | Data Time: 25.32 (25.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 2.22e+00 (2.22e+00)
INFO 2025-06-30 17:17:24,820 train_utils.py: 271: Train Epoch: [2][ 10/100] | Batch Time: 1.22 (3.51) | Data Time: 0.00 (2.31) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 2.88e+00 (1.64e+00)
INFO 2025-06-30 17:17:34,776 train_utils.py: 271: Train Epoch: [2][ 20/100] | Batch Time: 0.87 (2.31) | Data Time: 0.00 (1.21) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 1.77e+00 (1.97e+00)
INFO 2025-06-30 17:17:42,016 train_utils.py: 271: Train Epoch: [2][ 30/100] | Batch Time: 0.78 (1.80) | Data Time: 0.00 (0.82) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 2.26e+00 (1.80e+00)
INFO 2025-06-30 17:17:49,726 train_utils.py: 271: Train Epoch: [2][ 40/100] | Batch Time: 0.67 (1.55) | Data Time: 0.00 (0.62) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 1.46e+00 (1.67e+00)
INFO 2025-06-30 17:17:56,341 train_utils.py: 271: Train Epoch: [2][ 50/100] | Batch Time: 0.59 (1.38) | Data Time: 0.00 (0.50) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 1.34e+00 (1.57e+00)
INFO 2025-06-30 17:18:03,049 train_utils.py: 271: Train Epoch: [2][ 60/100] | Batch Time: 0.60 (1.26) | Data Time: 0.00 (0.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 1.59e+00 (1.54e+00)
INFO 2025-06-30 17:19:33,475 train_utils.py: 271: Train Epoch: [2][ 70/100] | Batch Time: 1.52 (2.36) | Data Time: 0.00 (0.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 4.71e-01 (1.47e+00)
INFO 2025-06-30 17:19:42,315 train_utils.py: 271: Train Epoch: [2][ 80/100] | Batch Time: 0.58 (2.17) | Data Time: 0.00 (0.31) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 1.13e+00 (1.40e+00)
INFO 2025-06-30 17:19:46,438 train_utils.py: 271: Train Epoch: [2][ 90/100] | Batch Time: 0.40 (1.98) | Data Time: 0.00 (0.28) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 1.71e+00 (1.37e+00)
INFO 2025-06-30 17:19:51,866 trainer.py: 950: Estimated time remaining: 00d 01h 53m
INFO 2025-06-30 17:19:51,868 trainer.py: 892: Synchronizing meters
INFO 2025-06-30 17:19:51,869 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.3640920257568359, 'Losses/train_all_loss_mask': 0.014148819785332308, 'Losses/train_all_loss_dice': 0.6692620547115803, 'Losses/train_all_loss_iou': 0.41185357604175804, 'Losses/train_all_loss_class': 1.430511176181426e-08, 'Losses/train_all_core_loss': 1.3640920257568359, 'Trainer/where': 0.07475000000000001, 'Trainer/epoch': 2, 'Trainer/steps_train': 300}
INFO 2025-06-30 17:20:18,739 train_utils.py: 271: Train Epoch: [3][  0/100] | Batch Time: 25.62 (25.62) | Data Time: 24.13 (24.13) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 4.35e+00 (4.35e+00)
INFO 2025-06-30 17:20:29,528 train_utils.py: 271: Train Epoch: [3][ 10/100] | Batch Time: 1.20 (3.31) | Data Time: 0.00 (2.20) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 6.40e-01 (1.61e+00)
INFO 2025-06-30 17:20:37,651 train_utils.py: 271: Train Epoch: [3][ 20/100] | Batch Time: 0.58 (2.12) | Data Time: 0.00 (1.15) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 5.60e-01 (1.25e+00)
INFO 2025-06-30 17:20:46,625 train_utils.py: 271: Train Epoch: [3][ 30/100] | Batch Time: 1.24 (1.73) | Data Time: 0.00 (0.78) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 2.42e+00 (1.42e+00)
INFO 2025-06-30 17:20:53,490 train_utils.py: 271: Train Epoch: [3][ 40/100] | Batch Time: 0.65 (1.47) | Data Time: 0.00 (0.59) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 1.07e+00 (1.49e+00)
INFO 2025-06-30 17:21:01,288 train_utils.py: 271: Train Epoch: [3][ 50/100] | Batch Time: 0.86 (1.34) | Data Time: 0.00 (0.48) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 1.96e+00 (1.37e+00)
INFO 2025-06-30 17:21:08,164 train_utils.py: 271: Train Epoch: [3][ 60/100] | Batch Time: 0.86 (1.23) | Data Time: 0.00 (0.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 1.49e+00 (1.34e+00)
INFO 2025-06-30 17:21:14,792 train_utils.py: 271: Train Epoch: [3][ 70/100] | Batch Time: 0.67 (1.15) | Data Time: 0.00 (0.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 9.44e-01 (1.41e+00)
INFO 2025-06-30 17:21:21,644 train_utils.py: 271: Train Epoch: [3][ 80/100] | Batch Time: 0.62 (1.09) | Data Time: 0.00 (0.30) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 8.45e-01 (1.41e+00)
INFO 2025-06-30 17:21:25,872 train_utils.py: 271: Train Epoch: [3][ 90/100] | Batch Time: 0.40 (1.02) | Data Time: 0.00 (0.27) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 1.02e+00 (1.42e+00)
INFO 2025-06-30 17:21:31,784 trainer.py: 950: Estimated time remaining: 00d 00h 58m
INFO 2025-06-30 17:21:31,786 trainer.py: 892: Synchronizing meters
INFO 2025-06-30 17:21:31,787 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.3792920246720315, 'Losses/train_all_loss_mask': 0.014625280545442366, 'Losses/train_all_loss_dice': 0.6590578991919755, 'Losses/train_all_loss_iou': 0.4277284413576126, 'Losses/train_all_loss_class': 7.828064596537843e-08, 'Losses/train_all_core_loss': 1.3792920246720315, 'Trainer/where': 0.09975, 'Trainer/epoch': 3, 'Trainer/steps_train': 400}
INFO 2025-06-30 17:22:00,619 train_utils.py: 271: Train Epoch: [4][  0/100] | Batch Time: 27.57 (27.57) | Data Time: 25.65 (25.65) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 4.80e-01 (4.80e-01)
INFO 2025-06-30 17:22:15,263 train_utils.py: 271: Train Epoch: [4][ 10/100] | Batch Time: 0.84 (3.84) | Data Time: 0.00 (2.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 6.06e-01 (9.74e-01)
INFO 2025-06-30 17:22:22,620 train_utils.py: 271: Train Epoch: [4][ 20/100] | Batch Time: 0.64 (2.36) | Data Time: 0.00 (1.23) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 8.66e-01 (1.25e+00)
INFO 2025-06-30 17:22:30,173 train_utils.py: 271: Train Epoch: [4][ 30/100] | Batch Time: 1.00 (1.84) | Data Time: 0.00 (0.83) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 1.30e+00 (1.19e+00)
INFO 2025-06-30 17:22:37,051 train_utils.py: 271: Train Epoch: [4][ 40/100] | Batch Time: 0.80 (1.56) | Data Time: 0.00 (0.63) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 4.50e-01 (1.10e+00)
INFO 2025-06-30 17:22:43,914 train_utils.py: 271: Train Epoch: [4][ 50/100] | Batch Time: 0.49 (1.39) | Data Time: 0.00 (0.51) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 3.04e+00 (1.17e+00)
INFO 2025-06-30 17:22:49,879 train_utils.py: 271: Train Epoch: [4][ 60/100] | Batch Time: 0.59 (1.26) | Data Time: 0.00 (0.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 9.77e-01 (1.09e+00)
INFO 2025-06-30 17:22:56,394 train_utils.py: 271: Train Epoch: [4][ 70/100] | Batch Time: 0.71 (1.17) | Data Time: 0.00 (0.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 5.17e-01 (1.15e+00)
INFO 2025-06-30 17:23:02,245 train_utils.py: 271: Train Epoch: [4][ 80/100] | Batch Time: 0.48 (1.10) | Data Time: 0.00 (0.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 1.75e+00 (1.18e+00)
INFO 2025-06-30 17:23:06,350 train_utils.py: 271: Train Epoch: [4][ 90/100] | Batch Time: 0.39 (1.03) | Data Time: 0.00 (0.28) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 8.74e-01 (1.17e+00)
INFO 2025-06-30 17:23:11,328 trainer.py: 950: Estimated time remaining: 00d 00h 56m
INFO 2025-06-30 17:23:11,330 trainer.py: 892: Synchronizing meters
INFO 2025-06-30 17:23:11,330 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.1296328112483025, 'Losses/train_all_loss_mask': 0.013753569648251869, 'Losses/train_all_loss_dice': 0.5322731925547123, 'Losses/train_all_loss_iou': 0.3222879336029291, 'Losses/train_all_loss_class': 2.944456716136301e-07, 'Losses/train_all_core_loss': 1.1296328112483025, 'Trainer/where': 0.12475, 'Trainer/epoch': 4, 'Trainer/steps_train': 500}
INFO 2025-06-30 17:23:34,193 train_utils.py: 271: Train Epoch: [5][  0/100] | Batch Time: 21.80 (21.80) | Data Time: 20.69 (20.69) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 6.77e-01 (6.77e-01)
INFO 2025-06-30 17:23:43,159 train_utils.py: 271: Train Epoch: [5][ 10/100] | Batch Time: 1.06 (2.80) | Data Time: 0.00 (1.88) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 2.56e-01 (8.74e-01)
INFO 2025-06-30 17:23:50,723 train_utils.py: 271: Train Epoch: [5][ 20/100] | Batch Time: 0.82 (1.83) | Data Time: 0.00 (0.99) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 1.32e+00 (1.08e+00)
INFO 2025-06-30 17:23:57,367 train_utils.py: 271: Train Epoch: [5][ 30/100] | Batch Time: 0.77 (1.45) | Data Time: 0.00 (0.67) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 7.58e-01 (1.09e+00)
INFO 2025-06-30 17:24:03,840 train_utils.py: 271: Train Epoch: [5][ 40/100] | Batch Time: 0.80 (1.25) | Data Time: 0.00 (0.51) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 5.80e-01 (1.06e+00)
INFO 2025-06-30 17:24:09,835 train_utils.py: 271: Train Epoch: [5][ 50/100] | Batch Time: 0.56 (1.13) | Data Time: 0.00 (0.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 1.04e+00 (1.02e+00)
INFO 2025-06-30 17:24:16,277 train_utils.py: 271: Train Epoch: [5][ 60/100] | Batch Time: 0.68 (1.05) | Data Time: 0.00 (0.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 2.91e-01 (1.00e+00)
INFO 2025-06-30 17:24:22,108 train_utils.py: 271: Train Epoch: [5][ 70/100] | Batch Time: 0.57 (0.98) | Data Time: 0.00 (0.29) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 3.53e-01 (9.59e-01)
INFO 2025-06-30 17:24:27,742 train_utils.py: 271: Train Epoch: [5][ 80/100] | Batch Time: 0.51 (0.93) | Data Time: 0.00 (0.26) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 3.19e+00 (1.01e+00)
INFO 2025-06-30 17:24:31,991 train_utils.py: 271: Train Epoch: [5][ 90/100] | Batch Time: 0.39 (0.87) | Data Time: 0.00 (0.23) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 7.45e-01 (1.05e+00)
INFO 2025-06-30 17:24:45,596 trainer.py: 950: Estimated time remaining: 00d 00h 47m
INFO 2025-06-30 17:25:56,581 trainer.py: 892: Synchronizing meters
INFO 2025-06-30 17:25:56,594 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.0514441844820976, 'Losses/train_all_loss_mask': 0.011735029687406496, 'Losses/train_all_loss_dice': 0.501698411628604, 'Losses/train_all_loss_iou': 0.3150451678223908, 'Losses/train_all_loss_class': 1.5497203378345148e-08, 'Losses/train_all_core_loss': 1.0514441844820976, 'Trainer/where': 0.14975, 'Trainer/epoch': 5, 'Trainer/steps_train': 600}
INFO 2025-06-30 18:18:43,180 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 18:18:43,182 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 18:18:43,182 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=34101
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 18:18:43,184 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 18:18:43,186 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 18:18:43,694 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 18:18:43,697 trainer.py:1059: ====================
INFO 2025-06-30 18:18:43,697 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 18:18:43,698 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 18:18:43,702 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 18:18:43,703 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 18:18:43,703 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 18:18:43,704 trainer.py:1069: ====================
INFO 2025-06-30 18:18:43,708 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 18:18:43,708 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 18:18:43,795 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 18:18:43,795 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 18:18:43,795 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 18:18:43,795 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 18:18:43,795 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 18:18:43,799 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 18:18:43,811 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 18:18:44,486 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 18:18:44,488 trainer.py: 423: Resuming training from E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/checkpoints\checkpoint.pt
INFO 2025-06-30 18:19:07,078 train_utils.py: 271: Train Epoch: [6][  0/100] | Batch Time: 22.13 (22.13) | Data Time: 15.51 (15.51) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 1.32e+00 (1.32e+00)
INFO 2025-06-30 18:19:13,640 train_utils.py: 271: Train Epoch: [6][ 10/100] | Batch Time: 0.59 (2.61) | Data Time: 0.00 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 2.92e+00 (1.58e+00)
INFO 2025-06-30 18:19:19,691 train_utils.py: 271: Train Epoch: [6][ 20/100] | Batch Time: 0.56 (1.65) | Data Time: 0.00 (0.74) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 3.58e+00 (1.90e+00)
INFO 2025-06-30 18:19:25,842 train_utils.py: 271: Train Epoch: [6][ 30/100] | Batch Time: 0.62 (1.32) | Data Time: 0.00 (0.50) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 3.50e+00 (4.31e+00)
INFO 2025-06-30 18:19:32,154 train_utils.py: 271: Train Epoch: [6][ 40/100] | Batch Time: 0.62 (1.15) | Data Time: 0.00 (0.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 2.29e+00 (3.97e+00)
INFO 2025-06-30 18:19:38,662 train_utils.py: 271: Train Epoch: [6][ 50/100] | Batch Time: 0.65 (1.05) | Data Time: 0.00 (0.31) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 1.67e+00 (3.89e+00)
INFO 2025-06-30 18:19:44,789 train_utils.py: 271: Train Epoch: [6][ 60/100] | Batch Time: 0.52 (0.98) | Data Time: 0.00 (0.26) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 1.78e+00 (3.83e+00)
INFO 2025-06-30 18:19:50,826 train_utils.py: 271: Train Epoch: [6][ 70/100] | Batch Time: 0.65 (0.93) | Data Time: 0.00 (0.22) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 2.06e+00 (3.59e+00)
INFO 2025-06-30 18:19:56,678 train_utils.py: 271: Train Epoch: [6][ 80/100] | Batch Time: 0.49 (0.89) | Data Time: 0.00 (0.19) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 2.26e+00 (3.43e+00)
INFO 2025-06-30 18:20:00,819 train_utils.py: 271: Train Epoch: [6][ 90/100] | Batch Time: 0.38 (0.83) | Data Time: 0.00 (0.17) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 2.02e+00 (3.29e+00)
INFO 2025-06-30 18:20:05,622 trainer.py: 950: Estimated time remaining: 00d 00h 43m
INFO 2025-06-30 18:20:05,622 trainer.py: 892: Synchronizing meters
INFO 2025-06-30 18:20:05,623 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 3.2385627022385597, 'Losses/train_all_loss_mask': 0.047461676395032557, 'Losses/train_all_loss_dice': 1.3502115835249424, 'Losses/train_all_loss_iou': 0.939116381071508, 'Losses/train_all_loss_class': 1.2142820690286272e-06, 'Losses/train_all_core_loss': 3.2385627022385597, 'Trainer/where': 0.17475000000000002, 'Trainer/epoch': 6, 'Trainer/steps_train': 700}
INFO 2025-06-30 18:20:25,597 train_utils.py: 271: Train Epoch: [7][  0/100] | Batch Time: 19.08 (19.08) | Data Time: 18.22 (18.22) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 2.15e+00 (2.15e+00)
INFO 2025-06-30 18:20:34,313 train_utils.py: 271: Train Epoch: [7][ 10/100] | Batch Time: 0.92 (2.53) | Data Time: 0.00 (1.66) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 4.45e+00 (2.77e+00)
INFO 2025-06-30 18:20:41,707 train_utils.py: 271: Train Epoch: [7][ 20/100] | Batch Time: 0.79 (1.68) | Data Time: 0.00 (0.87) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 1.24e+00 (2.25e+00)
INFO 2025-06-30 18:20:48,261 train_utils.py: 271: Train Epoch: [7][ 30/100] | Batch Time: 0.58 (1.35) | Data Time: 0.00 (0.59) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 2.18e+00 (2.46e+00)
INFO 2025-06-30 18:20:54,333 train_utils.py: 271: Train Epoch: [7][ 40/100] | Batch Time: 0.64 (1.17) | Data Time: 0.00 (0.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 2.42e+00 (2.74e+00)
INFO 2025-06-30 18:21:00,229 train_utils.py: 271: Train Epoch: [7][ 50/100] | Batch Time: 0.51 (1.05) | Data Time: 0.00 (0.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 4.98e+00 (2.74e+00)
INFO 2025-06-30 18:21:06,204 train_utils.py: 271: Train Epoch: [7][ 60/100] | Batch Time: 0.66 (0.98) | Data Time: 0.00 (0.30) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 1.95e+00 (2.73e+00)
INFO 2025-06-30 18:21:12,245 train_utils.py: 271: Train Epoch: [7][ 70/100] | Batch Time: 0.61 (0.93) | Data Time: 0.00 (0.26) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 2.47e+00 (2.96e+00)
INFO 2025-06-30 18:21:18,435 train_utils.py: 271: Train Epoch: [7][ 80/100] | Batch Time: 0.60 (0.89) | Data Time: 0.00 (0.23) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 1.27e+00 (2.85e+00)
INFO 2025-06-30 18:21:22,725 train_utils.py: 271: Train Epoch: [7][ 90/100] | Batch Time: 0.40 (0.84) | Data Time: 0.00 (0.20) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 7.34e-01 (2.75e+00)
INFO 2025-06-30 18:21:27,454 trainer.py: 950: Estimated time remaining: 00d 00h 42m
INFO 2025-06-30 18:21:27,454 trainer.py: 892: Synchronizing meters
INFO 2025-06-30 18:21:27,454 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.7121699914336204, 'Losses/train_all_loss_mask': 0.03393961136462167, 'Losses/train_all_loss_dice': 1.2396769742667675, 'Losses/train_all_loss_iou': 0.7936966040730477, 'Losses/train_all_loss_class': 4.1972851613536476e-06, 'Losses/train_all_core_loss': 2.7121699914336204, 'Trainer/where': 0.19975, 'Trainer/epoch': 7, 'Trainer/steps_train': 800}
INFO 2025-06-30 18:21:45,995 train_utils.py: 271: Train Epoch: [8][  0/100] | Batch Time: 17.70 (17.70) | Data Time: 16.68 (16.68) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 8.59e-01 (8.59e-01)
INFO 2025-06-30 18:21:54,528 train_utils.py: 271: Train Epoch: [8][ 10/100] | Batch Time: 0.81 (2.39) | Data Time: 0.00 (1.52) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 2.31e+00 (3.25e+00)
INFO 2025-06-30 18:22:02,121 train_utils.py: 271: Train Epoch: [8][ 20/100] | Batch Time: 0.77 (1.61) | Data Time: 0.00 (0.80) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 1.15e+00 (2.58e+00)
INFO 2025-06-30 18:22:08,739 train_utils.py: 271: Train Epoch: [8][ 30/100] | Batch Time: 0.69 (1.30) | Data Time: 0.00 (0.54) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 2.04e+00 (2.30e+00)
INFO 2025-06-30 18:22:14,876 train_utils.py: 271: Train Epoch: [8][ 40/100] | Batch Time: 0.61 (1.14) | Data Time: 0.00 (0.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 4.39e-01 (2.32e+00)
INFO 2025-06-30 18:22:20,948 train_utils.py: 271: Train Epoch: [8][ 50/100] | Batch Time: 0.58 (1.03) | Data Time: 0.00 (0.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 1.03e+00 (2.25e+00)
INFO 2025-06-30 18:22:27,780 train_utils.py: 271: Train Epoch: [8][ 60/100] | Batch Time: 0.86 (0.98) | Data Time: 0.00 (0.27) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 2.09e+00 (2.32e+00)
INFO 2025-06-30 18:22:33,757 train_utils.py: 271: Train Epoch: [8][ 70/100] | Batch Time: 0.51 (0.92) | Data Time: 0.00 (0.24) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 1.18e+00 (2.26e+00)
INFO 2025-06-30 18:22:39,915 train_utils.py: 271: Train Epoch: [8][ 80/100] | Batch Time: 0.58 (0.88) | Data Time: 0.00 (0.21) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 2.39e+00 (2.33e+00)
INFO 2025-06-30 18:22:44,037 train_utils.py: 271: Train Epoch: [8][ 90/100] | Batch Time: 0.40 (0.83) | Data Time: 0.00 (0.18) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 1.19e+00 (2.53e+00)
INFO 2025-06-30 18:22:48,795 trainer.py: 950: Estimated time remaining: 00d 00h 40m
INFO 2025-06-30 18:22:48,795 trainer.py: 892: Synchronizing meters
INFO 2025-06-30 18:22:48,796 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.4840800631046296, 'Losses/train_all_loss_mask': 0.030748206243151797, 'Losses/train_all_loss_dice': 1.0941738560795784, 'Losses/train_all_loss_iou': 0.7749420876801014, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 2.4840800631046296, 'Trainer/where': 0.22475, 'Trainer/epoch': 8, 'Trainer/steps_train': 900}
INFO 2025-06-30 18:23:14,101 train_utils.py: 271: Train Epoch: [9][  0/100] | Batch Time: 24.12 (24.12) | Data Time: 22.94 (22.94) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 2.94e+00 (2.94e+00)
INFO 2025-06-30 18:23:24,419 train_utils.py: 271: Train Epoch: [9][ 10/100] | Batch Time: 1.06 (3.13) | Data Time: 0.00 (2.09) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 1.30e+00 (1.67e+00)
INFO 2025-06-30 18:23:32,046 train_utils.py: 271: Train Epoch: [9][ 20/100] | Batch Time: 0.70 (2.00) | Data Time: 0.00 (1.09) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 5.87e+00 (1.96e+00)
INFO 2025-06-30 18:23:38,264 train_utils.py: 271: Train Epoch: [9][ 30/100] | Batch Time: 0.52 (1.56) | Data Time: 0.00 (0.74) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 1.06e+00 (1.86e+00)
INFO 2025-06-30 18:23:44,607 train_utils.py: 271: Train Epoch: [9][ 40/100] | Batch Time: 0.58 (1.33) | Data Time: 0.00 (0.56) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 9.70e-01 (1.78e+00)
INFO 2025-06-30 18:23:51,200 train_utils.py: 271: Train Epoch: [9][ 50/100] | Batch Time: 0.64 (1.20) | Data Time: 0.00 (0.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 6.12e+00 (1.91e+00)
INFO 2025-06-30 18:23:57,262 train_utils.py: 271: Train Epoch: [9][ 60/100] | Batch Time: 0.63 (1.10) | Data Time: 0.00 (0.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 1.51e+00 (2.26e+00)
INFO 2025-06-30 18:24:03,508 train_utils.py: 271: Train Epoch: [9][ 70/100] | Batch Time: 0.64 (1.04) | Data Time: 0.00 (0.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 6.90e+00 (2.58e+00)
INFO 2025-06-30 18:24:09,362 train_utils.py: 271: Train Epoch: [9][ 80/100] | Batch Time: 0.49 (0.98) | Data Time: 0.00 (0.28) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 1.24e+00 (2.49e+00)
INFO 2025-06-30 18:24:13,444 train_utils.py: 271: Train Epoch: [9][ 90/100] | Batch Time: 0.40 (0.92) | Data Time: 0.00 (0.25) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 2.32e+00 (2.48e+00)
INFO 2025-06-30 18:24:18,459 trainer.py: 950: Estimated time remaining: 00d 00h 43m
INFO 2025-06-30 18:24:18,460 trainer.py: 892: Synchronizing meters
INFO 2025-06-30 18:24:18,460 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.561145223379135, 'Losses/train_all_loss_mask': 0.03136059800279327, 'Losses/train_all_loss_dice': 1.129614834934473, 'Losses/train_all_loss_iou': 0.8043184223771095, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 2.561145223379135, 'Trainer/where': 0.24975, 'Trainer/epoch': 9, 'Trainer/steps_train': 1000}
INFO 2025-06-30 18:24:37,906 train_utils.py: 271: Train Epoch: [10][  0/100] | Batch Time: 18.57 (18.57) | Data Time: 17.50 (17.50) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 2.25e+00 (2.25e+00)
INFO 2025-06-30 18:24:47,045 train_utils.py: 271: Train Epoch: [10][ 10/100] | Batch Time: 0.78 (2.52) | Data Time: 0.00 (1.59) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 1.15e+00 (2.58e+00)
INFO 2025-06-30 18:24:54,713 train_utils.py: 271: Train Epoch: [10][ 20/100] | Batch Time: 0.71 (1.68) | Data Time: 0.00 (0.84) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 2.11e+00 (2.45e+00)
INFO 2025-06-30 18:25:01,255 train_utils.py: 271: Train Epoch: [10][ 30/100] | Batch Time: 0.57 (1.35) | Data Time: 0.00 (0.57) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 9.83e-01 (2.21e+00)
INFO 2025-06-30 18:25:07,381 train_utils.py: 271: Train Epoch: [10][ 40/100] | Batch Time: 0.61 (1.17) | Data Time: 0.00 (0.43) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 1.35e+00 (2.10e+00)
INFO 2025-06-30 18:25:16,265 train_utils.py: 271: Train Epoch: [10][ 50/100] | Batch Time: 0.76 (1.12) | Data Time: 0.00 (0.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 1.30e+00 (2.12e+00)
INFO 2025-06-30 18:25:23,218 train_utils.py: 271: Train Epoch: [10][ 60/100] | Batch Time: 0.66 (1.05) | Data Time: 0.00 (0.29) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 1.29e+00 (2.04e+00)
INFO 2025-06-30 18:25:30,001 train_utils.py: 271: Train Epoch: [10][ 70/100] | Batch Time: 0.75 (1.00) | Data Time: 0.00 (0.25) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 8.12e-01 (2.02e+00)
INFO 2025-06-30 18:25:36,142 train_utils.py: 271: Train Epoch: [10][ 80/100] | Batch Time: 0.53 (0.95) | Data Time: 0.00 (0.22) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 2.06e+00 (1.95e+00)
INFO 2025-06-30 18:25:40,305 train_utils.py: 271: Train Epoch: [10][ 90/100] | Batch Time: 0.39 (0.89) | Data Time: 0.00 (0.19) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 1.67e+00 (2.07e+00)
INFO 2025-06-30 18:25:45,142 trainer.py: 950: Estimated time remaining: 00d 00h 40m
INFO 2025-06-30 18:25:45,143 trainer.py: 892: Synchronizing meters
INFO 2025-06-30 18:25:45,143 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.0372874942421912, 'Losses/train_all_loss_mask': 0.022899371642852204, 'Losses/train_all_loss_dice': 0.9491356678307057, 'Losses/train_all_loss_iou': 0.6301643927395344, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 2.0372874942421912, 'Trainer/where': 0.27475, 'Trainer/epoch': 10, 'Trainer/steps_train': 1100}
INFO 2025-06-30 18:26:04,868 train_utils.py: 271: Train Epoch: [11][  0/100] | Batch Time: 18.84 (18.84) | Data Time: 17.78 (17.78) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 6.78e-01 (6.78e-01)
INFO 2025-06-30 18:32:46,412 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-06-30 18:32:46,413 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-06-30 18:32:46,413 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\WINDOWS\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14264_1592913036=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=69D67gETAiUKD1FhCB1W8tpIpFMms0VJo5VRNnibDWSj6pqPm6FKcg5sl0YflPH4
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=55055
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=7c135cdb-e643-4af0-8bba-e3511f80d85d
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\WINDOWS
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-06-30 18:32:46,414 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 18:32:46,415 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-06-30 18:32:47,130 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-06-30 18:32:47,134 trainer.py:1059: ====================
INFO 2025-06-30 18:32:47,134 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-06-30 18:32:47,136 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-06-30 18:32:47,139 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-06-30 18:32:47,139 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-06-30 18:32:47,139 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-06-30 18:32:47,140 trainer.py:1069: ====================
INFO 2025-06-30 18:32:47,143 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-06-30 18:32:47,143 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 18:32:47,237 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-06-30 18:32:47,237 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-06-30 18:32:47,237 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-06-30 18:32:47,238 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-06-30 18:32:47,238 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-06-30 18:32:47,240 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-06-30 18:32:47,253 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-06-30 18:32:47,919 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-06-30 18:32:47,921 trainer.py: 423: Resuming training from E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/checkpoints\checkpoint.pt
INFO 2025-06-30 18:32:52,107 train_utils.py: 271: Train Epoch: [11][  0/100] | Batch Time: 3.66 (3.66) | Data Time: 1.53 (1.53) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 4.92e-01 (4.92e-01)
INFO 2025-07-01 18:00:15,216 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-07-01 18:00:15,219 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-07-01 18:00:15,219 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\Administrator\AppData\Roaming
CLASSPATH=.;D:\exetwo\java8jdk\lib\dt.jar;D:\exetwo\java8jdk\lib\tools.jar;D:\exetwo\lingo\Lingo18.jar
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=ANNAJI
COMSPEC=C:\Windows\system32\cmd.exe
CONDA_DEFAULT_ENV=yolo11
CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
CONDA_PREFIX=D:\exe_c\anaconda3\envs\yolo11
CONDA_PREFIX_1=D:\exe_c\anaconda3
CONDA_PROMPT_MODIFIER=(yolo11) 
CONDA_PYTHON_EXE=D:\exe_c\anaconda3\python.exe
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
CUDA_PATH_V11_6=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_14292_1592913036=1
GOOGLE_CLOUD_PROJECT=micro-progress-464103-j4
HDC_SERVER_PORT=65037
HOMEDRIVE=C:
HOMEPATH=\Users\Administrator
HYDRA_FULL_ERROR=1
IGCCSVC_DB=AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAA2CtV5izAakm1meu0w48m+QQAAAACAAAAAAAQZgAAAAEAACAAAADJw1PMry0xYYp9ppJnD+Nrz4IpJsOCZx6/baasALKjGgAAAAAOgAAAAAIAACAAAABPDKXN7bq16NnQrVz9ApmIuzVUcq1B6IeXVlYePMDxwWAAAAATsM13V6jF4xJUpDJcTlJ5+tW02Sxob1eVfxTAi1OjtSHRKECSVXnxQzDOcZPV0WgYXnG7myr+VA06CIiKAJI7kXaexH8orYez/12R2V6a6diJ4Ro9l2zjgVCFS1yFtsJAAAAABDPPKRaP0hCWD1ZRtLQjsOj/pCW9KPFsuar6WlzoPqieNT7DJb3Do8/UT3B8ngRJo4uTqIjgNmwAnkOtgqg0Eg==
INTELLIJ IDEA=D:\exetwo\IntelliJ IDEA 2023.3.6\bin;
INTELLIJ IDEA COMMUNITY EDITION=D:\exetwo\IntelliJ IDEA Community Edition 2023.3.6\bin;
JAVA_HOME=D:\exetwo\java8jdk
JETBRAINS RIDER=D:\exetwo\JetBrains Rider 2024.2.1\bin;
JETBRAINS_INTELLIJ_COMMAND_END_MARKER=v0lykiSCKmoim2NX7D0Psjk3u6rbTrHvdV7GG7uZv4onP0EFAAl3bx9W5ZbBXN4s
LINGO64_18_HOME=D:\exetwo\lingo\
LOCALAPPDATA=C:\Users\Administrator\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\ANNAJI
MASTER_ADDR=localhost
MASTER_PORT=27992
MYSQL_HOME=D:\exetwo\mysql\bin
NODE_PATH=D:\exe_c\nodejs\node_modules
NUMBER_OF_PROCESSORS=20
NVTOOLSEXT_PATH=C:\Program Files\NVIDIA Corporation\NvToolsExt\
ONEDRIVE=C:\Users\Administrator\OneDrive
ONEDRIVECONSUMER=C:\Users\Administrator\OneDrive
OS=Windows_NT
PATH=D:\exe_c\anaconda3\envs\yolo11;D:\exe_c\anaconda3\envs\yolo11\Library\mingw-w64\bin;D:\exe_c\anaconda3\envs\yolo11\Library\usr\bin;D:\exe_c\anaconda3\envs\yolo11\Library\bin;D:\exe_c\anaconda3\envs\yolo11\Scripts;D:\exe_c\anaconda3\envs\yolo11\bin;D:\exe_c\anaconda3\condabin;d:\exetwo\cursor\resources\app\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\Client S;D:\exe_c\nodejs;D:\exe_c\Git\cmd;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\extras\CUPTI\lib64;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\libnvvp;C:\Windows\system32;C:\Windows;D:\exes\mingw64\bin;D:\exe_c\anaconda3\Library\mingw-w64\bin;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\exetwo\java8jdk\bin;D:\exe_c\anaconda3;D:\exe_c\anaconda3\Scripts;D:\exe_c\anaconda3\Library\bin;D:\exe_c\bandzip\Bandizip;D:\exe_c\Git\cmd;D:\exe_c\Git\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2022.1.1;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6;D:\exe_c\nodejs;D:\exe_c\nodejs\node_modules\node_global;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn;C:\Program Files\Microsoft SQL Server\160\Tools\Bin;%DevEco Studio%;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx86\x64;D:\exetwo\cursor\resources\app\bin;C:\Users\Administrator\AppData\Roaming\Python\Python39\Scripts;C:\Users\Administrator\AppData\Roaming\npm;D:\exetwo\PyCharm 2025.1.2\bin;.
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=9a03
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PSEXECUTIONPOLICYPREFERENCE=Bypass
PSMODULEPATH=C:\Users\Administrator\Documents\WindowsPowerShell\Modules;C:\Program Files\WindowsPowerShell\Modules;C:\Windows\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\PowerShell\Modules\
PUBLIC=C:\Users\Public
PYCHARM=D:\exetwo\PyCharm 2025.1.2\bin;
PYCHARM COMMUNITY EDITION=D:\exe_c\pycharm\PyCharm Community Edition 2023.1.4\bin;
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\Windows
TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
TERMINAL_EMULATOR=JetBrains-JediTerm
TERM_SESSION_ID=b9df3766-cc69-4d06-b93b-1ba91714438b
TESSDATA_PREFIX=D:\exetwo\tesseractocr\tessdata
TMP=C:\Users\ADMINI~1\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=ANNAJI
USERDOMAIN_ROAMINGPROFILE=ANNAJI
USERNAME=Administrator
USERPROFILE=C:\Users\Administrator
WINDIR=C:\Windows
WORLD_SIZE=1
ZES_ENABLE_SYSMAN=1
_CONDA_EXE=D:\exe_c\anaconda3\Scripts\conda.exe
_CONDA_ROOT=D:\exe_c\anaconda3

INFO 2025-07-01 18:00:15,221 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-07-01 18:00:15,222 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/tensorboard
INFO 2025-07-01 18:00:16,147 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-07-01 18:00:16,151 trainer.py:1059: ====================
INFO 2025-07-01 18:00:16,151 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-07-01 18:00:16,154 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-07-01 18:00:16,160 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-07-01 18:00:16,161 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-07-01 18:00:16,161 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-07-01 18:00:16,161 trainer.py:1069: ====================
INFO 2025-07-01 18:00:16,166 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-07-01 18:00:16,166 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-07-01 18:00:16,255 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-07-01 18:00:16,255 finetune_trainer.py:  22: >>>>> Running SAMFinetuneTrainer: Freezing model parts for fine-tuning. <<<<<
INFO 2025-07-01 18:00:16,255 finetune_trainer.py:  28: Freezing Image Encoder...
INFO 2025-07-01 18:00:16,257 finetune_trainer.py:  32: Enabling training for Prompt Encoder...
INFO 2025-07-01 18:00:16,257 finetune_trainer.py:  36: Enabling training for Mask Decoder...
INFO 2025-07-01 18:00:16,259 finetune_trainer.py:  43: Fine-tuning with 11,743,362 trainable parameters out of 80,850,178 total parameters.
INFO 2025-07-01 18:00:16,272 finetune_trainer.py:  59: >>>>> SAMFinetuneTrainer: Optimizer constructed for fine-tuning. <<<<<
INFO 2025-07-01 18:00:17,066 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-07-01 18:00:17,068 trainer.py: 423: Resuming training from E:\stv\ml\paper\yolo11\ultralytics-yolo11-main\sam2-main\sam2_logs\sam2.1_hiera_b+_waste_finetune/checkpoints\checkpoint.pt
INFO 2025-07-01 18:00:21,252 train_utils.py: 271: Train Epoch: [11][  0/100] | Batch Time: 3.62 (3.62) | Data Time: 1.41 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 4.91e-01 (4.91e-01)
INFO 2025-07-01 18:00:40,143 train_utils.py: 271: Train Epoch: [11][ 10/100] | Batch Time: 1.84 (2.05) | Data Time: 1.45 (1.46) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 2.02e+00 (3.07e+00)
INFO 2025-07-01 18:00:58,378 train_utils.py: 271: Train Epoch: [11][ 20/100] | Batch Time: 1.80 (1.94) | Data Time: 1.40 (1.44) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 3.43e+00 (2.80e+00)
INFO 2025-07-01 18:01:16,827 train_utils.py: 271: Train Epoch: [11][ 30/100] | Batch Time: 1.85 (1.91) | Data Time: 1.46 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 2.63e+00 (2.42e+00)
INFO 2025-07-01 18:01:34,385 train_utils.py: 271: Train Epoch: [11][ 40/100] | Batch Time: 1.63 (1.87) | Data Time: 1.25 (1.43) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 2.07e+00 (2.62e+00)
INFO 2025-07-01 18:01:50,916 train_utils.py: 271: Train Epoch: [11][ 50/100] | Batch Time: 1.57 (1.83) | Data Time: 1.18 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 1.45e+00 (2.46e+00)
INFO 2025-07-01 18:02:08,044 train_utils.py: 271: Train Epoch: [11][ 60/100] | Batch Time: 1.71 (1.81) | Data Time: 1.32 (1.39) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 5.91e+00 (2.45e+00)
INFO 2025-07-01 18:02:25,634 train_utils.py: 271: Train Epoch: [11][ 70/100] | Batch Time: 1.99 (1.80) | Data Time: 1.60 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 1.51e+00 (2.30e+00)
INFO 2025-07-01 18:02:43,112 train_utils.py: 271: Train Epoch: [11][ 80/100] | Batch Time: 1.83 (1.80) | Data Time: 1.45 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 1.27e+00 (2.25e+00)
WARNING 2025-07-01 18:02:55,428 transforms.py: 349: Skip RandomAffine for zero-area mask in first frame after 1 tentatives
INFO 2025-07-01 18:02:59,031 train_utils.py: 271: Train Epoch: [11][ 90/100] | Batch Time: 1.54 (1.77) | Data Time: 1.16 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 1.39e+00 (2.38e+00)
INFO 2025-07-01 18:03:14,254 trainer.py: 950: Estimated time remaining: 00d 01h 22m
INFO 2025-07-01 18:03:14,254 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:03:14,255 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.4276029336452485, 'Losses/train_all_loss_mask': 0.03301255288301036, 'Losses/train_all_loss_dice': 1.0345668071508407, 'Losses/train_all_loss_iou': 0.7327850875258446, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 2.4276029336452485, 'Trainer/where': 0.29975, 'Trainer/epoch': 11, 'Trainer/steps_train': 1200}
INFO 2025-07-01 18:03:16,713 train_utils.py: 271: Train Epoch: [12][  0/100] | Batch Time: 1.72 (1.72) | Data Time: 1.31 (1.31) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 9.47e-01 (9.47e-01)
INFO 2025-07-01 18:03:33,486 train_utils.py: 271: Train Epoch: [12][ 10/100] | Batch Time: 1.66 (1.68) | Data Time: 1.27 (1.29) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 2.32e+00 (1.96e+00)
INFO 2025-07-01 18:03:50,786 train_utils.py: 271: Train Epoch: [12][ 20/100] | Batch Time: 1.92 (1.70) | Data Time: 1.49 (1.31) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 7.06e-01 (2.71e+00)
INFO 2025-07-01 18:04:08,604 train_utils.py: 271: Train Epoch: [12][ 30/100] | Batch Time: 1.88 (1.73) | Data Time: 1.48 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 3.51e+00 (2.63e+00)
INFO 2025-07-01 18:04:29,071 train_utils.py: 271: Train Epoch: [12][ 40/100] | Batch Time: 1.86 (1.81) | Data Time: 1.48 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 2.34e+00 (2.52e+00)
INFO 2025-07-01 18:04:49,315 train_utils.py: 271: Train Epoch: [12][ 50/100] | Batch Time: 2.02 (1.85) | Data Time: 1.63 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 2.84e+00 (2.46e+00)
INFO 2025-07-01 18:05:06,529 train_utils.py: 271: Train Epoch: [12][ 60/100] | Batch Time: 1.77 (1.83) | Data Time: 1.39 (1.43) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 3.05e+00 (2.33e+00)
INFO 2025-07-01 18:05:25,509 train_utils.py: 271: Train Epoch: [12][ 70/100] | Batch Time: 2.00 (1.84) | Data Time: 1.60 (1.44) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 2.96e+00 (2.26e+00)
INFO 2025-07-01 18:05:45,421 train_utils.py: 271: Train Epoch: [12][ 80/100] | Batch Time: 2.02 (1.86) | Data Time: 1.56 (1.46) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 8.16e-01 (2.37e+00)
INFO 2025-07-01 18:06:02,711 train_utils.py: 271: Train Epoch: [12][ 90/100] | Batch Time: 1.52 (1.84) | Data Time: 1.15 (1.44) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 1.05e+00 (2.26e+00)
INFO 2025-07-01 18:06:18,542 trainer.py: 950: Estimated time remaining: 00d 01h 22m
INFO 2025-07-01 18:06:18,542 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:06:18,543 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.255297081172466, 'Losses/train_all_loss_mask': 0.028214643208775668, 'Losses/train_all_loss_dice': 0.975224097520113, 'Losses/train_all_loss_iou': 0.7157801142334939, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 2.255297081172466, 'Trainer/where': 0.32475, 'Trainer/epoch': 12, 'Trainer/steps_train': 1300}
INFO 2025-07-01 18:06:21,058 train_utils.py: 271: Train Epoch: [13][  0/100] | Batch Time: 1.78 (1.78) | Data Time: 1.35 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 1.16e+00 (1.16e+00)
INFO 2025-07-01 18:06:38,054 train_utils.py: 271: Train Epoch: [13][ 10/100] | Batch Time: 1.76 (1.71) | Data Time: 1.38 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 3.53e+00 (1.81e+00)
INFO 2025-07-01 18:06:54,951 train_utils.py: 271: Train Epoch: [13][ 20/100] | Batch Time: 1.76 (1.70) | Data Time: 1.38 (1.31) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 1.22e+00 (1.89e+00)
INFO 2025-07-01 18:07:12,542 train_utils.py: 271: Train Epoch: [13][ 30/100] | Batch Time: 1.72 (1.72) | Data Time: 1.35 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 3.97e-01 (1.75e+00)
INFO 2025-07-01 18:07:30,424 train_utils.py: 271: Train Epoch: [13][ 40/100] | Batch Time: 1.72 (1.74) | Data Time: 1.34 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 1.53e+00 (1.68e+00)
INFO 2025-07-01 18:07:48,854 train_utils.py: 271: Train Epoch: [13][ 50/100] | Batch Time: 1.91 (1.76) | Data Time: 1.52 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 2.24e+00 (2.34e+00)
INFO 2025-07-01 18:08:05,599 train_utils.py: 271: Train Epoch: [13][ 60/100] | Batch Time: 1.69 (1.74) | Data Time: 1.30 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 1.18e+00 (2.34e+00)
INFO 2025-07-01 18:08:22,354 train_utils.py: 271: Train Epoch: [13][ 70/100] | Batch Time: 1.62 (1.73) | Data Time: 1.23 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 6.23e-01 (2.30e+00)
INFO 2025-07-01 18:08:39,351 train_utils.py: 271: Train Epoch: [13][ 80/100] | Batch Time: 1.85 (1.73) | Data Time: 1.46 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 1.33e+00 (2.28e+00)
INFO 2025-07-01 18:08:57,010 train_utils.py: 271: Train Epoch: [13][ 90/100] | Batch Time: 1.60 (1.73) | Data Time: 1.21 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 2.11e+00 (2.27e+00)
INFO 2025-07-01 18:09:12,471 trainer.py: 950: Estimated time remaining: 00d 01h 15m
INFO 2025-07-01 18:09:12,471 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:09:12,471 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.243347838819027, 'Losses/train_all_loss_mask': 0.029626980863977224, 'Losses/train_all_loss_dice': 0.9594573737680911, 'Losses/train_all_loss_iou': 0.691350819915533, 'Losses/train_all_loss_class': 3.5762776917636076e-09, 'Losses/train_all_core_loss': 2.243347838819027, 'Trainer/where': 0.34975, 'Trainer/epoch': 13, 'Trainer/steps_train': 1400}
INFO 2025-07-01 18:09:14,789 train_utils.py: 271: Train Epoch: [14][  0/100] | Batch Time: 1.55 (1.55) | Data Time: 1.13 (1.13) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 5.64e+00 (5.64e+00)
INFO 2025-07-01 18:09:32,058 train_utils.py: 271: Train Epoch: [14][ 10/100] | Batch Time: 1.83 (1.71) | Data Time: 1.44 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 1.18e+00 (2.66e+00)
INFO 2025-07-01 18:09:49,029 train_utils.py: 271: Train Epoch: [14][ 20/100] | Batch Time: 1.88 (1.70) | Data Time: 1.50 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 1.59e+00 (2.76e+00)
INFO 2025-07-01 18:10:05,856 train_utils.py: 271: Train Epoch: [14][ 30/100] | Batch Time: 1.78 (1.70) | Data Time: 1.38 (1.31) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 2.12e+00 (2.28e+00)
INFO 2025-07-01 18:10:24,728 train_utils.py: 271: Train Epoch: [14][ 40/100] | Batch Time: 1.88 (1.74) | Data Time: 1.48 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 3.40e+00 (2.24e+00)
INFO 2025-07-01 18:10:42,017 train_utils.py: 271: Train Epoch: [14][ 50/100] | Batch Time: 1.82 (1.74) | Data Time: 1.42 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 8.80e-01 (2.08e+00)
INFO 2025-07-01 18:11:00,028 train_utils.py: 271: Train Epoch: [14][ 60/100] | Batch Time: 1.98 (1.75) | Data Time: 1.58 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 6.26e-01 (1.99e+00)
INFO 2025-07-01 18:11:17,184 train_utils.py: 271: Train Epoch: [14][ 70/100] | Batch Time: 1.56 (1.75) | Data Time: 1.18 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 6.56e-01 (1.94e+00)
INFO 2025-07-01 18:11:34,486 train_utils.py: 271: Train Epoch: [14][ 80/100] | Batch Time: 1.72 (1.74) | Data Time: 1.34 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 1.17e+00 (1.84e+00)
INFO 2025-07-01 18:11:52,653 train_utils.py: 271: Train Epoch: [14][ 90/100] | Batch Time: 1.94 (1.75) | Data Time: 1.55 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 7.00e+00 (1.92e+00)
INFO 2025-07-01 18:12:08,017 trainer.py: 950: Estimated time remaining: 00d 01h 12m
INFO 2025-07-01 18:12:08,017 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:12:08,018 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.9078632137179374, 'Losses/train_all_loss_mask': 0.02205201082630083, 'Losses/train_all_loss_dice': 0.8693781884014606, 'Losses/train_all_loss_iou': 0.5974448063969612, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 1.9078632137179374, 'Trainer/where': 0.37475, 'Trainer/epoch': 14, 'Trainer/steps_train': 1500}
INFO 2025-07-01 18:12:10,406 train_utils.py: 271: Train Epoch: [15][  0/100] | Batch Time: 1.61 (1.61) | Data Time: 1.20 (1.20) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 1.53e+00 (1.53e+00)
INFO 2025-07-01 18:12:28,331 train_utils.py: 271: Train Epoch: [15][ 10/100] | Batch Time: 1.92 (1.78) | Data Time: 1.53 (1.39) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 4.11e-01 (2.02e+00)
INFO 2025-07-01 18:12:46,325 train_utils.py: 271: Train Epoch: [15][ 20/100] | Batch Time: 1.64 (1.79) | Data Time: 1.25 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 1.99e+00 (1.90e+00)
INFO 2025-07-01 18:13:03,598 train_utils.py: 271: Train Epoch: [15][ 30/100] | Batch Time: 1.84 (1.77) | Data Time: 1.46 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 4.68e-01 (1.90e+00)
INFO 2025-07-01 18:13:21,233 train_utils.py: 271: Train Epoch: [15][ 40/100] | Batch Time: 1.73 (1.77) | Data Time: 1.35 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 1.04e+00 (1.85e+00)
INFO 2025-07-01 18:13:39,162 train_utils.py: 271: Train Epoch: [15][ 50/100] | Batch Time: 1.82 (1.77) | Data Time: 1.43 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 1.41e+00 (1.77e+00)
INFO 2025-07-01 18:13:56,536 train_utils.py: 271: Train Epoch: [15][ 60/100] | Batch Time: 1.77 (1.77) | Data Time: 1.38 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 1.31e+00 (1.68e+00)
INFO 2025-07-01 18:14:13,377 train_utils.py: 271: Train Epoch: [15][ 70/100] | Batch Time: 1.84 (1.75) | Data Time: 1.46 (1.37) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 3.48e-01 (1.79e+00)
INFO 2025-07-01 18:14:30,470 train_utils.py: 271: Train Epoch: [15][ 80/100] | Batch Time: 1.66 (1.75) | Data Time: 1.27 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 1.89e+00 (1.73e+00)
INFO 2025-07-01 18:14:47,735 train_utils.py: 271: Train Epoch: [15][ 90/100] | Batch Time: 1.60 (1.75) | Data Time: 1.22 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 1.27e+00 (1.70e+00)
INFO 2025-07-01 18:15:04,040 trainer.py: 950: Estimated time remaining: 00d 01h 10m
INFO 2025-07-01 18:15:04,040 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:15:04,040 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.7836733731627463, 'Losses/train_all_loss_mask': 0.021467301044613123, 'Losses/train_all_loss_dice': 0.7745333701372147, 'Losses/train_all_loss_iou': 0.5797939261049032, 'Losses/train_all_loss_class': 5.4041439838670156e-08, 'Losses/train_all_core_loss': 1.7836733731627463, 'Trainer/where': 0.39975, 'Trainer/epoch': 15, 'Trainer/steps_train': 1600}
INFO 2025-07-01 18:15:06,740 train_utils.py: 271: Train Epoch: [16][  0/100] | Batch Time: 1.87 (1.87) | Data Time: 1.45 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 6.21e+00 (6.21e+00)
INFO 2025-07-01 18:15:25,797 train_utils.py: 271: Train Epoch: [16][ 10/100] | Batch Time: 1.78 (1.90) | Data Time: 1.38 (1.50) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 1.03e+00 (2.10e+00)
INFO 2025-07-01 18:15:44,218 train_utils.py: 271: Train Epoch: [16][ 20/100] | Batch Time: 1.83 (1.87) | Data Time: 1.44 (1.48) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 1.27e+00 (1.58e+00)
INFO 2025-07-01 18:16:03,214 train_utils.py: 271: Train Epoch: [16][ 30/100] | Batch Time: 1.67 (1.88) | Data Time: 1.28 (1.49) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 2.03e+00 (1.84e+00)
INFO 2025-07-01 18:16:20,878 train_utils.py: 271: Train Epoch: [16][ 40/100] | Batch Time: 1.70 (1.85) | Data Time: 1.31 (1.46) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 6.29e-01 (1.67e+00)
WARNING 2025-07-01 18:16:25,050 transforms.py: 349: Skip RandomAffine for zero-area mask in first frame after 1 tentatives
INFO 2025-07-01 18:16:37,642 train_utils.py: 271: Train Epoch: [16][ 50/100] | Batch Time: 1.69 (1.82) | Data Time: 1.30 (1.43) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 3.15e+00 (1.75e+00)
INFO 2025-07-01 18:16:54,980 train_utils.py: 271: Train Epoch: [16][ 60/100] | Batch Time: 2.09 (1.81) | Data Time: 1.68 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 2.99e+00 (1.94e+00)
INFO 2025-07-01 18:17:12,692 train_utils.py: 271: Train Epoch: [16][ 70/100] | Batch Time: 1.75 (1.80) | Data Time: 1.37 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 9.82e-01 (1.93e+00)
INFO 2025-07-01 18:17:29,954 train_utils.py: 271: Train Epoch: [16][ 80/100] | Batch Time: 1.86 (1.79) | Data Time: 1.47 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 2.17e+00 (2.08e+00)
INFO 2025-07-01 18:17:47,136 train_utils.py: 271: Train Epoch: [16][ 90/100] | Batch Time: 1.55 (1.78) | Data Time: 1.18 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 7.51e-01 (2.14e+00)
INFO 2025-07-01 18:18:02,940 trainer.py: 950: Estimated time remaining: 00d 01h 08m
INFO 2025-07-01 18:18:02,940 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:18:02,940 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.080896754562855, 'Losses/train_all_loss_mask': 0.026809468930587173, 'Losses/train_all_loss_dice': 0.9073693984746933, 'Losses/train_all_loss_iou': 0.6373379685729742, 'Losses/train_all_loss_class': 1.907347702001516e-08, 'Losses/train_all_core_loss': 2.080896754562855, 'Trainer/where': 0.42474999999999996, 'Trainer/epoch': 16, 'Trainer/steps_train': 1700}
INFO 2025-07-01 18:18:05,341 train_utils.py: 271: Train Epoch: [17][  0/100] | Batch Time: 1.62 (1.62) | Data Time: 1.20 (1.20) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 6.20e-01 (6.20e-01)
INFO 2025-07-01 18:18:23,319 train_utils.py: 271: Train Epoch: [17][ 10/100] | Batch Time: 1.75 (1.78) | Data Time: 1.37 (1.39) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 1.38e+00 (1.05e+00)
INFO 2025-07-01 18:18:40,933 train_utils.py: 271: Train Epoch: [17][ 20/100] | Batch Time: 1.71 (1.77) | Data Time: 1.31 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 1.01e+00 (1.10e+00)
INFO 2025-07-01 18:18:58,477 train_utils.py: 271: Train Epoch: [17][ 30/100] | Batch Time: 1.84 (1.77) | Data Time: 1.45 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 3.29e+00 (1.18e+00)
INFO 2025-07-01 18:19:16,413 train_utils.py: 271: Train Epoch: [17][ 40/100] | Batch Time: 1.68 (1.77) | Data Time: 1.29 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 1.01e+00 (1.17e+00)
INFO 2025-07-01 18:19:33,616 train_utils.py: 271: Train Epoch: [17][ 50/100] | Batch Time: 1.78 (1.76) | Data Time: 1.39 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 9.71e-01 (1.64e+00)
INFO 2025-07-01 18:19:51,400 train_utils.py: 271: Train Epoch: [17][ 60/100] | Batch Time: 1.77 (1.77) | Data Time: 1.38 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 5.43e-01 (1.77e+00)
INFO 2025-07-01 18:20:08,802 train_utils.py: 271: Train Epoch: [17][ 70/100] | Batch Time: 1.65 (1.76) | Data Time: 1.26 (1.37) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 1.86e+00 (1.71e+00)
INFO 2025-07-01 18:20:26,624 train_utils.py: 271: Train Epoch: [17][ 80/100] | Batch Time: 1.59 (1.76) | Data Time: 1.21 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 9.68e-01 (1.71e+00)
INFO 2025-07-01 18:20:43,749 train_utils.py: 271: Train Epoch: [17][ 90/100] | Batch Time: 1.64 (1.76) | Data Time: 1.25 (1.37) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 4.55e-01 (1.72e+00)
INFO 2025-07-01 18:20:59,746 trainer.py: 950: Estimated time remaining: 00d 01h 04m
INFO 2025-07-01 18:20:59,747 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:20:59,747 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.7194021260738372, 'Losses/train_all_loss_mask': 0.021633355466183276, 'Losses/train_all_loss_dice': 0.7731385438144207, 'Losses/train_all_loss_iou': 0.5135964626818895, 'Losses/train_all_loss_class': 3.9736427481784633e-10, 'Losses/train_all_core_loss': 1.7194021260738372, 'Trainer/where': 0.44975, 'Trainer/epoch': 17, 'Trainer/steps_train': 1800}
INFO 2025-07-01 18:21:02,129 train_utils.py: 271: Train Epoch: [18][  0/100] | Batch Time: 1.60 (1.60) | Data Time: 1.19 (1.19) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 1.08e+00 (1.08e+00)
INFO 2025-07-01 18:21:19,002 train_utils.py: 271: Train Epoch: [18][ 10/100] | Batch Time: 1.78 (1.68) | Data Time: 1.39 (1.29) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 1.24e+00 (2.53e+00)
INFO 2025-07-01 18:21:37,036 train_utils.py: 271: Train Epoch: [18][ 20/100] | Batch Time: 2.01 (1.74) | Data Time: 1.61 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 39m | Losses/train_all_loss: 3.80e-01 (2.09e+00)
INFO 2025-07-01 18:21:54,478 train_utils.py: 271: Train Epoch: [18][ 30/100] | Batch Time: 1.58 (1.74) | Data Time: 1.19 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 39m | Losses/train_all_loss: 3.31e+00 (2.09e+00)
INFO 2025-07-01 18:22:11,302 train_utils.py: 271: Train Epoch: [18][ 40/100] | Batch Time: 1.61 (1.73) | Data Time: 1.22 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 39m | Losses/train_all_loss: 7.73e-01 (1.92e+00)
INFO 2025-07-01 18:22:28,394 train_utils.py: 271: Train Epoch: [18][ 50/100] | Batch Time: 1.62 (1.72) | Data Time: 1.20 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 40m | Losses/train_all_loss: 4.11e-01 (1.82e+00)
INFO 2025-07-01 18:22:46,808 train_utils.py: 271: Train Epoch: [18][ 60/100] | Batch Time: 1.89 (1.74) | Data Time: 1.48 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 40m | Losses/train_all_loss: 1.07e+01 (1.86e+00)
INFO 2025-07-01 18:23:04,069 train_utils.py: 271: Train Epoch: [18][ 70/100] | Batch Time: 1.82 (1.74) | Data Time: 1.43 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 40m | Losses/train_all_loss: 2.53e+00 (1.76e+00)
INFO 2025-07-01 18:23:20,773 train_utils.py: 271: Train Epoch: [18][ 80/100] | Batch Time: 1.78 (1.73) | Data Time: 1.39 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 40m | Losses/train_all_loss: 2.25e+00 (1.90e+00)
INFO 2025-07-01 18:23:37,715 train_utils.py: 271: Train Epoch: [18][ 90/100] | Batch Time: 1.77 (1.73) | Data Time: 1.38 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 41m | Losses/train_all_loss: 5.38e-01 (1.90e+00)
INFO 2025-07-01 18:23:52,832 trainer.py: 950: Estimated time remaining: 00d 01h 00m
INFO 2025-07-01 18:23:52,833 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:23:52,833 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.9405434355139732, 'Losses/train_all_loss_mask': 0.02623669113847427, 'Losses/train_all_loss_dice': 0.8315213650465012, 'Losses/train_all_loss_iou': 0.5842882303521038, 'Losses/train_all_loss_class': 9.934103815112394e-09, 'Losses/train_all_core_loss': 1.9405434355139732, 'Trainer/where': 0.47474999999999995, 'Trainer/epoch': 18, 'Trainer/steps_train': 1900}
INFO 2025-07-01 18:23:55,198 train_utils.py: 271: Train Epoch: [19][  0/100] | Batch Time: 1.60 (1.60) | Data Time: 1.20 (1.20) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 41m | Losses/train_all_loss: 1.69e+00 (1.69e+00)
INFO 2025-07-01 18:24:12,736 train_utils.py: 271: Train Epoch: [19][ 10/100] | Batch Time: 1.92 (1.74) | Data Time: 1.54 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 41m | Losses/train_all_loss: 9.92e-01 (1.88e+00)
INFO 2025-07-01 18:24:29,055 train_utils.py: 271: Train Epoch: [19][ 20/100] | Batch Time: 1.49 (1.69) | Data Time: 1.12 (1.30) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 42m | Losses/train_all_loss: 1.96e-01 (1.42e+00)
INFO 2025-07-01 18:24:46,321 train_utils.py: 271: Train Epoch: [19][ 30/100] | Batch Time: 1.73 (1.70) | Data Time: 1.34 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 42m | Losses/train_all_loss: 7.50e-01 (1.57e+00)
INFO 2025-07-01 18:25:02,963 train_utils.py: 271: Train Epoch: [19][ 40/100] | Batch Time: 1.59 (1.69) | Data Time: 1.22 (1.31) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 42m | Losses/train_all_loss: 6.92e-01 (1.42e+00)
INFO 2025-07-01 18:25:19,584 train_utils.py: 271: Train Epoch: [19][ 50/100] | Batch Time: 1.59 (1.69) | Data Time: 1.21 (1.30) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 42m | Losses/train_all_loss: 1.18e+00 (1.42e+00)
INFO 2025-07-01 18:25:37,408 train_utils.py: 271: Train Epoch: [19][ 60/100] | Batch Time: 1.91 (1.70) | Data Time: 1.54 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 43m | Losses/train_all_loss: 2.59e+00 (1.58e+00)
INFO 2025-07-01 18:25:54,685 train_utils.py: 271: Train Epoch: [19][ 70/100] | Batch Time: 1.84 (1.71) | Data Time: 1.45 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 43m | Losses/train_all_loss: 1.85e+00 (1.52e+00)
INFO 2025-07-01 18:26:11,680 train_utils.py: 271: Train Epoch: [19][ 80/100] | Batch Time: 1.64 (1.70) | Data Time: 1.26 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 43m | Losses/train_all_loss: 1.45e+00 (1.55e+00)
INFO 2025-07-01 18:26:28,670 train_utils.py: 271: Train Epoch: [19][ 90/100] | Batch Time: 1.87 (1.70) | Data Time: 1.48 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 44m | Losses/train_all_loss: 1.17e+00 (1.62e+00)
INFO 2025-07-01 18:26:43,564 trainer.py: 950: Estimated time remaining: 00d 00h 56m
INFO 2025-07-01 18:26:43,564 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:26:43,565 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.599940935522318, 'Losses/train_all_loss_mask': 0.020155615718103946, 'Losses/train_all_loss_dice': 0.7139778763800859, 'Losses/train_all_loss_iou': 0.48285072766244413, 'Losses/train_all_loss_class': 7.947285496356927e-10, 'Losses/train_all_core_loss': 1.599940935522318, 'Trainer/where': 0.49974999999999997, 'Trainer/epoch': 19, 'Trainer/steps_train': 2000}
INFO 2025-07-01 18:26:46,018 train_utils.py: 271: Train Epoch: [20][  0/100] | Batch Time: 1.70 (1.70) | Data Time: 1.29 (1.29) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 44m | Losses/train_all_loss: 1.27e+00 (1.27e+00)
INFO 2025-07-01 18:27:03,384 train_utils.py: 271: Train Epoch: [20][ 10/100] | Batch Time: 1.74 (1.73) | Data Time: 1.35 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 44m | Losses/train_all_loss: 2.09e+00 (1.01e+00)
INFO 2025-07-01 18:27:20,964 train_utils.py: 271: Train Epoch: [20][ 20/100] | Batch Time: 1.62 (1.75) | Data Time: 1.23 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 44m | Losses/train_all_loss: 5.83e-01 (1.37e+00)
INFO 2025-07-01 18:27:39,656 train_utils.py: 271: Train Epoch: [20][ 30/100] | Batch Time: 1.76 (1.79) | Data Time: 1.37 (1.39) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 45m | Losses/train_all_loss: 6.69e-01 (1.92e+00)
INFO 2025-07-01 18:27:57,957 train_utils.py: 271: Train Epoch: [20][ 40/100] | Batch Time: 1.70 (1.80) | Data Time: 1.30 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 45m | Losses/train_all_loss: 1.01e+00 (1.87e+00)
INFO 2025-07-01 18:28:16,665 train_utils.py: 271: Train Epoch: [20][ 50/100] | Batch Time: 1.72 (1.81) | Data Time: 1.33 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 45m | Losses/train_all_loss: 5.33e-01 (1.87e+00)
INFO 2025-07-01 18:28:35,073 train_utils.py: 271: Train Epoch: [20][ 60/100] | Batch Time: 2.06 (1.82) | Data Time: 1.67 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 46m | Losses/train_all_loss: 1.48e+00 (2.05e+00)
INFO 2025-07-01 18:28:53,670 train_utils.py: 271: Train Epoch: [20][ 70/100] | Batch Time: 1.86 (1.82) | Data Time: 1.47 (1.43) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 46m | Losses/train_all_loss: 4.65e-01 (1.94e+00)
INFO 2025-07-01 18:29:12,477 train_utils.py: 271: Train Epoch: [20][ 80/100] | Batch Time: 1.79 (1.83) | Data Time: 1.41 (1.44) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 46m | Losses/train_all_loss: 1.00e+00 (1.84e+00)
INFO 2025-07-01 18:29:31,270 train_utils.py: 271: Train Epoch: [20][ 90/100] | Batch Time: 1.98 (1.83) | Data Time: 1.59 (1.44) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 47m | Losses/train_all_loss: 8.82e-01 (1.80e+00)
INFO 2025-07-01 18:29:47,284 trainer.py: 950: Estimated time remaining: 00d 00h 57m
INFO 2025-07-01 18:29:47,284 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:29:47,286 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.7716345793008805, 'Losses/train_all_loss_mask': 0.024076415341114626, 'Losses/train_all_loss_dice': 0.7736441504955291, 'Losses/train_all_loss_iou': 0.5164621210843324, 'Losses/train_all_loss_class': 1.1920928244535389e-09, 'Losses/train_all_core_loss': 1.7716345793008805, 'Trainer/where': 0.5247499999999999, 'Trainer/epoch': 20, 'Trainer/steps_train': 2100}
INFO 2025-07-01 18:29:49,808 train_utils.py: 271: Train Epoch: [21][  0/100] | Batch Time: 1.74 (1.74) | Data Time: 1.34 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 47m | Losses/train_all_loss: 6.78e-01 (6.78e-01)
INFO 2025-07-01 18:30:06,603 train_utils.py: 271: Train Epoch: [21][ 10/100] | Batch Time: 1.90 (1.69) | Data Time: 1.52 (1.30) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 47m | Losses/train_all_loss: 1.11e+00 (1.35e+00)
INFO 2025-07-01 18:30:23,803 train_utils.py: 271: Train Epoch: [21][ 20/100] | Batch Time: 1.75 (1.70) | Data Time: 1.37 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 48m | Losses/train_all_loss: 2.23e+00 (1.47e+00)
INFO 2025-07-01 18:30:41,568 train_utils.py: 271: Train Epoch: [21][ 30/100] | Batch Time: 1.93 (1.73) | Data Time: 1.54 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 48m | Losses/train_all_loss: 3.21e+00 (1.55e+00)
INFO 2025-07-01 18:30:59,070 train_utils.py: 271: Train Epoch: [21][ 40/100] | Batch Time: 1.69 (1.73) | Data Time: 1.31 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 48m | Losses/train_all_loss: 1.24e+00 (1.60e+00)
INFO 2025-07-01 18:31:15,844 train_utils.py: 271: Train Epoch: [21][ 50/100] | Batch Time: 1.54 (1.72) | Data Time: 1.17 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 48m | Losses/train_all_loss: 5.51e-01 (1.57e+00)
INFO 2025-07-01 18:31:32,920 train_utils.py: 271: Train Epoch: [21][ 60/100] | Batch Time: 1.90 (1.72) | Data Time: 1.51 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 49m | Losses/train_all_loss: 1.40e+00 (1.80e+00)
INFO 2025-07-01 18:31:49,333 train_utils.py: 271: Train Epoch: [21][ 70/100] | Batch Time: 1.54 (1.71) | Data Time: 1.15 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 49m | Losses/train_all_loss: 3.13e+00 (1.86e+00)
INFO 2025-07-01 18:32:06,990 train_utils.py: 271: Train Epoch: [21][ 80/100] | Batch Time: 2.00 (1.72) | Data Time: 1.59 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 49m | Losses/train_all_loss: 9.23e-01 (1.84e+00)
INFO 2025-07-01 18:32:28,829 train_utils.py: 271: Train Epoch: [21][ 90/100] | Batch Time: 2.35 (1.77) | Data Time: 1.90 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 50m | Losses/train_all_loss: 3.82e-01 (1.86e+00)
INFO 2025-07-01 18:32:45,976 trainer.py: 950: Estimated time remaining: 00d 00h 53m
INFO 2025-07-01 18:32:45,977 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:32:45,977 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.8241157004237174, 'Losses/train_all_loss_mask': 0.02367809650953859, 'Losses/train_all_loss_dice': 0.7968268804252148, 'Losses/train_all_loss_iou': 0.5537263976037502, 'Losses/train_all_loss_class': 5.050445475518472e-07, 'Losses/train_all_core_loss': 1.8241157004237174, 'Trainer/where': 0.54975, 'Trainer/epoch': 21, 'Trainer/steps_train': 2200}
INFO 2025-07-01 18:32:49,164 train_utils.py: 271: Train Epoch: [22][  0/100] | Batch Time: 2.07 (2.07) | Data Time: 1.61 (1.61) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 50m | Losses/train_all_loss: 1.72e+00 (1.72e+00)
INFO 2025-07-01 18:33:10,342 train_utils.py: 271: Train Epoch: [22][ 10/100] | Batch Time: 2.07 (2.11) | Data Time: 1.64 (1.67) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 50m | Losses/train_all_loss: 1.58e+00 (2.35e+00)
INFO 2025-07-01 18:33:30,085 train_utils.py: 271: Train Epoch: [22][ 20/100] | Batch Time: 1.77 (2.05) | Data Time: 1.34 (1.60) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 51m | Losses/train_all_loss: 4.85e-01 (2.46e+00)
INFO 2025-07-01 18:33:49,903 train_utils.py: 271: Train Epoch: [22][ 30/100] | Batch Time: 1.76 (2.03) | Data Time: 1.34 (1.59) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 51m | Losses/train_all_loss: 1.61e+00 (2.40e+00)
INFO 2025-07-01 18:34:09,366 train_utils.py: 271: Train Epoch: [22][ 40/100] | Batch Time: 2.02 (2.01) | Data Time: 1.59 (1.57) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 51m | Losses/train_all_loss: 8.88e-01 (2.18e+00)
INFO 2025-07-01 18:34:28,220 train_utils.py: 271: Train Epoch: [22][ 50/100] | Batch Time: 1.77 (1.98) | Data Time: 1.35 (1.55) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 52m | Losses/train_all_loss: 9.50e-01 (1.99e+00)
INFO 2025-07-01 18:34:48,327 train_utils.py: 271: Train Epoch: [22][ 60/100] | Batch Time: 1.93 (1.99) | Data Time: 1.51 (1.55) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 52m | Losses/train_all_loss: 5.18e-01 (1.87e+00)
INFO 2025-07-01 18:35:08,171 train_utils.py: 271: Train Epoch: [22][ 70/100] | Batch Time: 1.91 (1.99) | Data Time: 1.48 (1.55) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 52m | Losses/train_all_loss: 8.75e-01 (1.84e+00)
INFO 2025-07-01 18:35:28,121 train_utils.py: 271: Train Epoch: [22][ 80/100] | Batch Time: 1.90 (1.99) | Data Time: 1.48 (1.55) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 53m | Losses/train_all_loss: 1.66e+00 (1.84e+00)
INFO 2025-07-01 18:35:48,027 train_utils.py: 271: Train Epoch: [22][ 90/100] | Batch Time: 1.88 (1.99) | Data Time: 1.46 (1.55) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 53m | Losses/train_all_loss: 7.46e-01 (1.98e+00)
INFO 2025-07-01 18:36:04,386 trainer.py: 950: Estimated time remaining: 00d 00h 55m
INFO 2025-07-01 18:36:04,387 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:36:04,387 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.918254989683628, 'Losses/train_all_loss_mask': 0.023522643038304522, 'Losses/train_all_loss_dice': 0.848507893383503, 'Losses/train_all_loss_iou': 0.5992942374199629, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 1.918254989683628, 'Trainer/where': 0.57475, 'Trainer/epoch': 22, 'Trainer/steps_train': 2300}
INFO 2025-07-01 18:36:06,697 train_utils.py: 271: Train Epoch: [23][  0/100] | Batch Time: 1.54 (1.54) | Data Time: 1.13 (1.13) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 53m | Losses/train_all_loss: 9.69e-01 (9.69e-01)
INFO 2025-07-01 18:36:23,647 train_utils.py: 271: Train Epoch: [23][ 10/100] | Batch Time: 1.77 (1.68) | Data Time: 1.39 (1.29) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 54m | Losses/train_all_loss: 5.89e-01 (1.95e+00)
INFO 2025-07-01 18:36:41,174 train_utils.py: 271: Train Epoch: [23][ 20/100] | Batch Time: 1.71 (1.71) | Data Time: 1.32 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 54m | Losses/train_all_loss: 8.86e-01 (2.07e+00)
INFO 2025-07-01 18:36:58,707 train_utils.py: 271: Train Epoch: [23][ 30/100] | Batch Time: 1.57 (1.73) | Data Time: 1.19 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 54m | Losses/train_all_loss: 1.13e+00 (2.06e+00)
INFO 2025-07-01 18:37:16,087 train_utils.py: 271: Train Epoch: [23][ 40/100] | Batch Time: 1.67 (1.73) | Data Time: 1.25 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 54m | Losses/train_all_loss: 8.88e-01 (2.01e+00)
INFO 2025-07-01 18:37:34,266 train_utils.py: 271: Train Epoch: [23][ 50/100] | Batch Time: 2.01 (1.75) | Data Time: 1.58 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 55m | Losses/train_all_loss: 8.09e-01 (1.76e+00)
INFO 2025-07-01 18:37:53,362 train_utils.py: 271: Train Epoch: [23][ 60/100] | Batch Time: 1.70 (1.77) | Data Time: 1.28 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 55m | Losses/train_all_loss: 1.21e+00 (1.70e+00)
INFO 2025-07-01 18:38:13,544 train_utils.py: 271: Train Epoch: [23][ 70/100] | Batch Time: 1.91 (1.81) | Data Time: 1.50 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 55m | Losses/train_all_loss: 1.76e+00 (1.79e+00)
INFO 2025-07-01 18:38:31,491 train_utils.py: 271: Train Epoch: [23][ 80/100] | Batch Time: 1.88 (1.81) | Data Time: 1.50 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 56m | Losses/train_all_loss: 4.67e-01 (1.73e+00)
INFO 2025-07-01 18:38:49,083 train_utils.py: 271: Train Epoch: [23][ 90/100] | Batch Time: 1.91 (1.80) | Data Time: 1.52 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 56m | Losses/train_all_loss: 3.44e-01 (1.84e+00)
INFO 2025-07-01 18:39:04,977 trainer.py: 950: Estimated time remaining: 00d 00h 47m
INFO 2025-07-01 18:39:04,978 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:39:04,978 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.7638212910294533, 'Losses/train_all_loss_mask': 0.025026862155646087, 'Losses/train_all_loss_dice': 0.7277106529474259, 'Losses/train_all_loss_iou': 0.5355733861401677, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 1.7638212910294533, 'Trainer/where': 0.59975, 'Trainer/epoch': 23, 'Trainer/steps_train': 2400}
INFO 2025-07-01 18:39:07,549 train_utils.py: 271: Train Epoch: [24][  0/100] | Batch Time: 1.80 (1.80) | Data Time: 1.37 (1.37) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 56m | Losses/train_all_loss: 3.85e+00 (3.85e+00)
INFO 2025-07-01 18:39:23,914 train_utils.py: 271: Train Epoch: [24][ 10/100] | Batch Time: 1.77 (1.65) | Data Time: 1.39 (1.26) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 57m | Losses/train_all_loss: 3.56e+00 (1.88e+00)
INFO 2025-07-01 18:39:40,630 train_utils.py: 271: Train Epoch: [24][ 20/100] | Batch Time: 1.90 (1.66) | Data Time: 1.51 (1.27) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 57m | Losses/train_all_loss: 2.49e+00 (1.92e+00)
INFO 2025-07-01 18:39:57,627 train_utils.py: 271: Train Epoch: [24][ 30/100] | Batch Time: 1.54 (1.67) | Data Time: 1.16 (1.29) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 57m | Losses/train_all_loss: 7.45e-01 (1.59e+00)
INFO 2025-07-01 18:40:15,051 train_utils.py: 271: Train Epoch: [24][ 40/100] | Batch Time: 1.88 (1.69) | Data Time: 1.49 (1.30) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 57m | Losses/train_all_loss: 9.38e-01 (1.55e+00)
INFO 2025-07-01 18:40:32,246 train_utils.py: 271: Train Epoch: [24][ 50/100] | Batch Time: 1.74 (1.70) | Data Time: 1.34 (1.31) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 58m | Losses/train_all_loss: 9.51e-01 (1.73e+00)
INFO 2025-07-01 18:40:50,303 train_utils.py: 271: Train Epoch: [24][ 60/100] | Batch Time: 1.97 (1.71) | Data Time: 1.59 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 58m | Losses/train_all_loss: 1.06e+00 (1.76e+00)
INFO 2025-07-01 18:41:06,974 train_utils.py: 271: Train Epoch: [24][ 70/100] | Batch Time: 1.66 (1.71) | Data Time: 1.28 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 58m | Losses/train_all_loss: 6.22e-01 (1.72e+00)
INFO 2025-07-01 18:41:24,267 train_utils.py: 271: Train Epoch: [24][ 80/100] | Batch Time: 1.59 (1.71) | Data Time: 1.21 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 59m | Losses/train_all_loss: 4.92e-01 (1.65e+00)
INFO 2025-07-01 18:41:41,476 train_utils.py: 271: Train Epoch: [24][ 90/100] | Batch Time: 1.70 (1.71) | Data Time: 1.33 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 59m | Losses/train_all_loss: 6.28e+00 (1.68e+00)
INFO 2025-07-01 18:41:56,720 trainer.py: 950: Estimated time remaining: 00d 00h 42m
INFO 2025-07-01 18:41:56,721 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:41:56,721 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.6751557525992393, 'Losses/train_all_loss_mask': 0.02113217287173029, 'Losses/train_all_loss_dice': 0.7329677127301693, 'Losses/train_all_loss_iou': 0.5195445836335421, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 1.6751557525992393, 'Trainer/where': 0.6247499999999999, 'Trainer/epoch': 24, 'Trainer/steps_train': 2500}
INFO 2025-07-01 18:41:59,108 train_utils.py: 271: Train Epoch: [25][  0/100] | Batch Time: 1.62 (1.62) | Data Time: 1.20 (1.20) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 59m | Losses/train_all_loss: 1.45e+00 (1.45e+00)
INFO 2025-07-01 18:42:15,965 train_utils.py: 271: Train Epoch: [25][ 10/100] | Batch Time: 1.75 (1.68) | Data Time: 1.36 (1.29) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 00h 59m | Losses/train_all_loss: 5.00e-01 (1.28e+00)
INFO 2025-07-01 18:42:32,990 train_utils.py: 271: Train Epoch: [25][ 20/100] | Batch Time: 1.84 (1.69) | Data Time: 1.45 (1.30) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 00m | Losses/train_all_loss: 1.27e+00 (1.45e+00)
INFO 2025-07-01 18:42:50,991 train_utils.py: 271: Train Epoch: [25][ 30/100] | Batch Time: 1.97 (1.73) | Data Time: 1.57 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 00m | Losses/train_all_loss: 7.89e-01 (1.71e+00)
INFO 2025-07-01 18:43:09,602 train_utils.py: 271: Train Epoch: [25][ 40/100] | Batch Time: 1.96 (1.76) | Data Time: 1.57 (1.37) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 00m | Losses/train_all_loss: 1.59e+00 (1.92e+00)
INFO 2025-07-01 18:43:28,571 train_utils.py: 271: Train Epoch: [25][ 50/100] | Batch Time: 1.91 (1.79) | Data Time: 1.51 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 01m | Losses/train_all_loss: 1.52e+00 (1.85e+00)
INFO 2025-07-01 18:43:47,002 train_utils.py: 271: Train Epoch: [25][ 60/100] | Batch Time: 1.80 (1.80) | Data Time: 1.41 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 01m | Losses/train_all_loss: 4.23e-01 (1.76e+00)
INFO 2025-07-01 18:44:05,442 train_utils.py: 271: Train Epoch: [25][ 70/100] | Batch Time: 1.62 (1.80) | Data Time: 1.23 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 01m | Losses/train_all_loss: 4.05e+00 (1.85e+00)
INFO 2025-07-01 18:44:22,960 train_utils.py: 271: Train Epoch: [25][ 80/100] | Batch Time: 1.69 (1.80) | Data Time: 1.31 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 02m | Losses/train_all_loss: 2.22e+00 (1.72e+00)
INFO 2025-07-01 18:44:40,588 train_utils.py: 271: Train Epoch: [25][ 90/100] | Batch Time: 1.94 (1.79) | Data Time: 1.55 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 02m | Losses/train_all_loss: 7.10e+00 (1.74e+00)
INFO 2025-07-01 18:44:55,735 trainer.py: 950: Estimated time remaining: 00d 00h 41m
INFO 2025-07-01 18:44:55,735 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:44:55,736 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.783554467856884, 'Losses/train_all_loss_mask': 0.023015721026749817, 'Losses/train_all_loss_dice': 0.7860375075787306, 'Losses/train_all_loss_iou': 0.5372025403752922, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 1.783554467856884, 'Trainer/where': 0.6497499999999999, 'Trainer/epoch': 25, 'Trainer/steps_train': 2600}
INFO 2025-07-01 18:44:58,169 train_utils.py: 271: Train Epoch: [26][  0/100] | Batch Time: 1.67 (1.67) | Data Time: 1.27 (1.27) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 02m | Losses/train_all_loss: 5.91e-01 (5.91e-01)
INFO 2025-07-01 18:45:15,994 train_utils.py: 271: Train Epoch: [26][ 10/100] | Batch Time: 1.84 (1.77) | Data Time: 1.45 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 02m | Losses/train_all_loss: 7.93e-01 (1.07e+00)
INFO 2025-07-01 18:45:32,567 train_utils.py: 271: Train Epoch: [26][ 20/100] | Batch Time: 1.60 (1.72) | Data Time: 1.22 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 03m | Losses/train_all_loss: 6.55e-01 (1.15e+00)
INFO 2025-07-01 18:45:50,006 train_utils.py: 271: Train Epoch: [26][ 30/100] | Batch Time: 1.94 (1.73) | Data Time: 1.56 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 03m | Losses/train_all_loss: 6.56e-01 (1.14e+00)
INFO 2025-07-01 18:46:07,036 train_utils.py: 271: Train Epoch: [26][ 40/100] | Batch Time: 1.92 (1.72) | Data Time: 1.53 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 03m | Losses/train_all_loss: 6.78e-01 (1.18e+00)
INFO 2025-07-01 18:46:24,117 train_utils.py: 271: Train Epoch: [26][ 50/100] | Batch Time: 1.73 (1.72) | Data Time: 1.34 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 04m | Losses/train_all_loss: 3.96e+00 (1.20e+00)
INFO 2025-07-01 18:46:41,434 train_utils.py: 271: Train Epoch: [26][ 60/100] | Batch Time: 1.75 (1.72) | Data Time: 1.36 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 04m | Losses/train_all_loss: 1.06e+00 (1.20e+00)
INFO 2025-07-01 18:46:58,013 train_utils.py: 271: Train Epoch: [26][ 70/100] | Batch Time: 1.70 (1.71) | Data Time: 1.32 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 04m | Losses/train_all_loss: 8.55e-01 (1.32e+00)
INFO 2025-07-01 18:47:14,056 train_utils.py: 271: Train Epoch: [26][ 80/100] | Batch Time: 1.78 (1.70) | Data Time: 1.40 (1.31) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 04m | Losses/train_all_loss: 7.10e-01 (1.43e+00)
INFO 2025-07-01 18:47:30,724 train_utils.py: 271: Train Epoch: [26][ 90/100] | Batch Time: 1.55 (1.69) | Data Time: 1.17 (1.31) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 05m | Losses/train_all_loss: 2.71e-01 (1.38e+00)
INFO 2025-07-01 18:47:46,477 trainer.py: 950: Estimated time remaining: 00d 00h 36m
INFO 2025-07-01 18:47:46,478 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:47:46,478 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.3815554577112197, 'Losses/train_all_loss_mask': 0.017596098255598918, 'Losses/train_all_loss_dice': 0.6018290060013533, 'Losses/train_all_loss_iou': 0.4278044805303216, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 1.3815554577112197, 'Trainer/where': 0.67475, 'Trainer/epoch': 26, 'Trainer/steps_train': 2700}
INFO 2025-07-01 18:47:48,901 train_utils.py: 271: Train Epoch: [27][  0/100] | Batch Time: 1.67 (1.67) | Data Time: 1.27 (1.27) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 05m | Losses/train_all_loss: 4.47e-01 (4.47e-01)
INFO 2025-07-01 18:48:06,621 train_utils.py: 271: Train Epoch: [27][ 10/100] | Batch Time: 1.74 (1.76) | Data Time: 1.35 (1.38) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 05m | Losses/train_all_loss: 9.72e-01 (1.11e+00)
INFO 2025-07-01 18:48:23,306 train_utils.py: 271: Train Epoch: [27][ 20/100] | Batch Time: 1.56 (1.72) | Data Time: 1.19 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 06m | Losses/train_all_loss: 5.44e-01 (9.48e-01)
INFO 2025-07-01 18:48:40,694 train_utils.py: 271: Train Epoch: [27][ 30/100] | Batch Time: 1.76 (1.72) | Data Time: 1.38 (1.34) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 06m | Losses/train_all_loss: 1.36e+00 (1.02e+00)
INFO 2025-07-01 18:48:57,212 train_utils.py: 271: Train Epoch: [27][ 40/100] | Batch Time: 1.80 (1.71) | Data Time: 1.41 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 06m | Losses/train_all_loss: 2.50e+00 (1.01e+00)
INFO 2025-07-01 18:49:14,205 train_utils.py: 271: Train Epoch: [27][ 50/100] | Batch Time: 1.54 (1.71) | Data Time: 1.15 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 06m | Losses/train_all_loss: 1.82e+00 (1.15e+00)
INFO 2025-07-01 18:49:31,108 train_utils.py: 271: Train Epoch: [27][ 60/100] | Batch Time: 1.62 (1.70) | Data Time: 1.24 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 07m | Losses/train_all_loss: 1.02e+00 (1.25e+00)
WARNING 2025-07-01 18:49:33,770 transforms.py: 349: Skip RandomAffine for zero-area mask in first frame after 1 tentatives
INFO 2025-07-01 18:49:48,157 train_utils.py: 271: Train Epoch: [27][ 70/100] | Batch Time: 1.55 (1.70) | Data Time: 1.17 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 07m | Losses/train_all_loss: 1.13e+00 (1.34e+00)
INFO 2025-07-01 18:50:05,216 train_utils.py: 271: Train Epoch: [27][ 80/100] | Batch Time: 1.59 (1.70) | Data Time: 1.20 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 07m | Losses/train_all_loss: 1.95e+00 (1.36e+00)
INFO 2025-07-01 18:50:22,593 train_utils.py: 271: Train Epoch: [27][ 90/100] | Batch Time: 1.56 (1.71) | Data Time: 1.17 (1.32) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 08m | Losses/train_all_loss: 1.57e+00 (1.42e+00)
INFO 2025-07-01 18:50:38,580 trainer.py: 950: Estimated time remaining: 00d 00h 34m
INFO 2025-07-01 18:50:38,580 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:50:38,580 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.494226143360138, 'Losses/train_all_loss_mask': 0.016716010088566692, 'Losses/train_all_loss_dice': 0.7043773562461138, 'Losses/train_all_loss_iou': 0.45552857607603076, 'Losses/train_all_loss_class': 5.96046362488778e-09, 'Losses/train_all_core_loss': 1.494226143360138, 'Trainer/where': 0.69975, 'Trainer/epoch': 27, 'Trainer/steps_train': 2800}
INFO 2025-07-01 18:50:40,916 train_utils.py: 271: Train Epoch: [28][  0/100] | Batch Time: 1.59 (1.59) | Data Time: 1.17 (1.17) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 08m | Losses/train_all_loss: 2.63e-01 (2.63e-01)
INFO 2025-07-01 18:51:01,286 train_utils.py: 271: Train Epoch: [28][ 10/100] | Batch Time: 2.14 (2.00) | Data Time: 1.63 (1.46) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 08m | Losses/train_all_loss: 2.26e-01 (1.04e+00)
INFO 2025-07-01 18:51:21,191 train_utils.py: 271: Train Epoch: [28][ 20/100] | Batch Time: 2.18 (1.99) | Data Time: 1.66 (1.46) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 08m | Losses/train_all_loss: 3.11e+00 (1.10e+00)
INFO 2025-07-01 18:51:41,006 train_utils.py: 271: Train Epoch: [28][ 30/100] | Batch Time: 1.96 (1.99) | Data Time: 1.42 (1.46) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 09m | Losses/train_all_loss: 5.67e+00 (1.58e+00)
INFO 2025-07-01 18:52:00,582 train_utils.py: 271: Train Epoch: [28][ 40/100] | Batch Time: 1.94 (1.98) | Data Time: 1.41 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 09m | Losses/train_all_loss: 1.66e+00 (1.66e+00)
INFO 2025-07-01 18:52:20,307 train_utils.py: 271: Train Epoch: [28][ 50/100] | Batch Time: 1.94 (1.98) | Data Time: 1.41 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 09m | Losses/train_all_loss: 1.84e+00 (1.56e+00)
INFO 2025-07-01 18:52:39,188 train_utils.py: 271: Train Epoch: [28][ 60/100] | Batch Time: 1.78 (1.96) | Data Time: 1.24 (1.43) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 10m | Losses/train_all_loss: 1.44e+00 (1.51e+00)
INFO 2025-07-01 18:52:59,115 train_utils.py: 271: Train Epoch: [28][ 70/100] | Batch Time: 2.09 (1.97) | Data Time: 1.57 (1.43) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 10m | Losses/train_all_loss: 7.66e-01 (1.44e+00)
INFO 2025-07-01 18:53:17,716 train_utils.py: 271: Train Epoch: [28][ 80/100] | Batch Time: 1.61 (1.96) | Data Time: 1.22 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 10m | Losses/train_all_loss: 1.19e+00 (1.36e+00)
INFO 2025-07-01 18:53:36,633 train_utils.py: 271: Train Epoch: [28][ 90/100] | Batch Time: 1.82 (1.95) | Data Time: 1.27 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 11m | Losses/train_all_loss: 8.33e-01 (1.53e+00)
INFO 2025-07-01 18:53:55,053 trainer.py: 950: Estimated time remaining: 00d 00h 35m
INFO 2025-07-01 18:53:55,054 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:53:55,054 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.6541513718664647, 'Losses/train_all_loss_mask': 0.021727014857460744, 'Losses/train_all_loss_dice': 0.7129370755702257, 'Losses/train_all_loss_iou': 0.5066740020737052, 'Losses/train_all_loss_class': 3.9736427481784633e-10, 'Losses/train_all_core_loss': 1.6541513718664647, 'Trainer/where': 0.72475, 'Trainer/epoch': 28, 'Trainer/steps_train': 2900}
INFO 2025-07-01 18:53:57,898 train_utils.py: 271: Train Epoch: [29][  0/100] | Batch Time: 2.02 (2.02) | Data Time: 1.46 (1.46) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 11m | Losses/train_all_loss: 1.73e+00 (1.73e+00)
WARNING 2025-07-01 18:54:01,126 transforms.py: 349: Skip RandomAffine for zero-area mask in first frame after 1 tentatives
INFO 2025-07-01 18:54:17,692 train_utils.py: 271: Train Epoch: [29][ 10/100] | Batch Time: 1.73 (1.98) | Data Time: 1.21 (1.46) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 11m | Losses/train_all_loss: 7.17e+00 (2.00e+00)
INFO 2025-07-01 18:54:37,107 train_utils.py: 271: Train Epoch: [29][ 20/100] | Batch Time: 2.01 (1.96) | Data Time: 1.50 (1.44) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 12m | Losses/train_all_loss: 2.66e+00 (1.59e+00)
INFO 2025-07-01 18:54:55,464 train_utils.py: 271: Train Epoch: [29][ 30/100] | Batch Time: 1.76 (1.92) | Data Time: 1.23 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 12m | Losses/train_all_loss: 5.75e-01 (1.91e+00)
INFO 2025-07-01 18:55:15,022 train_utils.py: 271: Train Epoch: [29][ 40/100] | Batch Time: 1.92 (1.93) | Data Time: 1.40 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 12m | Losses/train_all_loss: 4.40e-01 (1.67e+00)
INFO 2025-07-01 18:55:34,480 train_utils.py: 271: Train Epoch: [29][ 50/100] | Batch Time: 2.08 (1.93) | Data Time: 1.53 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 13m | Losses/train_all_loss: 9.05e-01 (1.63e+00)
INFO 2025-07-01 18:55:52,819 train_utils.py: 271: Train Epoch: [29][ 60/100] | Batch Time: 2.01 (1.92) | Data Time: 1.48 (1.39) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 13m | Losses/train_all_loss: 5.67e-01 (1.62e+00)
INFO 2025-07-01 18:56:12,250 train_utils.py: 271: Train Epoch: [29][ 70/100] | Batch Time: 1.82 (1.92) | Data Time: 1.28 (1.39) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 13m | Losses/train_all_loss: 3.37e-01 (1.54e+00)
INFO 2025-07-01 18:56:31,677 train_utils.py: 271: Train Epoch: [29][ 80/100] | Batch Time: 2.16 (1.92) | Data Time: 1.63 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 14m | Losses/train_all_loss: 4.83e-01 (1.47e+00)
INFO 2025-07-01 18:56:50,904 train_utils.py: 271: Train Epoch: [29][ 90/100] | Batch Time: 1.80 (1.92) | Data Time: 1.28 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 14m | Losses/train_all_loss: 4.90e+00 (1.54e+00)
INFO 2025-07-01 18:57:08,507 trainer.py: 950: Estimated time remaining: 00d 00h 32m
INFO 2025-07-01 18:57:08,508 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 18:57:08,508 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.5949015310406685, 'Losses/train_all_loss_mask': 0.01962293930526357, 'Losses/train_all_loss_dice': 0.7006705013662576, 'Losses/train_all_loss_iou': 0.5017722345888614, 'Losses/train_all_loss_class': 2.7815491421279148e-09, 'Losses/train_all_core_loss': 1.5949015310406685, 'Trainer/where': 0.7497499999999999, 'Trainer/epoch': 29, 'Trainer/steps_train': 3000}
INFO 2025-07-01 18:57:11,095 train_utils.py: 271: Train Epoch: [30][  0/100] | Batch Time: 1.76 (1.76) | Data Time: 1.21 (1.21) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 14m | Losses/train_all_loss: 4.71e-01 (4.71e-01)
INFO 2025-07-01 18:57:30,166 train_utils.py: 271: Train Epoch: [30][ 10/100] | Batch Time: 1.82 (1.89) | Data Time: 1.29 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 15m | Losses/train_all_loss: 1.03e+00 (1.08e+00)
INFO 2025-07-01 18:57:50,100 train_utils.py: 271: Train Epoch: [30][ 20/100] | Batch Time: 1.98 (1.94) | Data Time: 1.44 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 15m | Losses/train_all_loss: 3.09e+00 (1.87e+00)
INFO 2025-07-01 18:58:09,605 train_utils.py: 271: Train Epoch: [30][ 30/100] | Batch Time: 2.07 (1.94) | Data Time: 1.55 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 15m | Losses/train_all_loss: 8.29e-01 (1.81e+00)
INFO 2025-07-01 18:58:28,482 train_utils.py: 271: Train Epoch: [30][ 40/100] | Batch Time: 1.89 (1.93) | Data Time: 1.37 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 16m | Losses/train_all_loss: 1.32e+00 (1.70e+00)
INFO 2025-07-01 18:58:48,650 train_utils.py: 271: Train Epoch: [30][ 50/100] | Batch Time: 1.96 (1.95) | Data Time: 1.44 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 16m | Losses/train_all_loss: 4.97e-01 (1.58e+00)
INFO 2025-07-01 18:59:08,355 train_utils.py: 271: Train Epoch: [30][ 60/100] | Batch Time: 2.12 (1.95) | Data Time: 1.59 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 16m | Losses/train_all_loss: 1.57e+00 (1.48e+00)
INFO 2025-07-01 18:59:27,498 train_utils.py: 271: Train Epoch: [30][ 70/100] | Batch Time: 1.92 (1.95) | Data Time: 1.40 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 17m | Losses/train_all_loss: 5.60e-01 (1.55e+00)
INFO 2025-07-01 18:59:46,922 train_utils.py: 271: Train Epoch: [30][ 80/100] | Batch Time: 2.07 (1.95) | Data Time: 1.55 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 17m | Losses/train_all_loss: 5.55e+00 (1.53e+00)
INFO 2025-07-01 19:00:06,766 train_utils.py: 271: Train Epoch: [30][ 90/100] | Batch Time: 1.81 (1.95) | Data Time: 1.27 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 17m | Losses/train_all_loss: 1.66e+00 (1.47e+00)
INFO 2025-07-01 19:00:23,657 trainer.py: 950: Estimated time remaining: 00d 00h 29m
INFO 2025-07-01 19:00:23,657 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 19:00:23,657 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.4482951952517034, 'Losses/train_all_loss_mask': 0.01717977202613838, 'Losses/train_all_loss_dice': 0.6603727678954602, 'Losses/train_all_loss_iou': 0.44432696580886843, 'Losses/train_all_loss_class': 1.072883442532202e-08, 'Losses/train_all_core_loss': 1.4482951952517034, 'Trainer/where': 0.7747499999999999, 'Trainer/epoch': 30, 'Trainer/steps_train': 3100}
INFO 2025-07-01 19:00:26,242 train_utils.py: 271: Train Epoch: [31][  0/100] | Batch Time: 1.78 (1.78) | Data Time: 1.23 (1.23) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 18m | Losses/train_all_loss: 9.19e-01 (9.19e-01)
INFO 2025-07-01 19:00:46,297 train_utils.py: 271: Train Epoch: [31][ 10/100] | Batch Time: 2.16 (1.98) | Data Time: 1.63 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 18m | Losses/train_all_loss: 8.57e-01 (1.00e+00)
INFO 2025-07-01 19:01:05,736 train_utils.py: 271: Train Epoch: [31][ 20/100] | Batch Time: 1.76 (1.97) | Data Time: 1.24 (1.44) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 18m | Losses/train_all_loss: 8.61e-01 (1.51e+00)
INFO 2025-07-01 19:01:25,659 train_utils.py: 271: Train Epoch: [31][ 30/100] | Batch Time: 2.02 (1.97) | Data Time: 1.49 (1.44) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 19m | Losses/train_all_loss: 9.32e-01 (1.38e+00)
INFO 2025-07-01 19:01:44,693 train_utils.py: 271: Train Epoch: [31][ 40/100] | Batch Time: 1.91 (1.96) | Data Time: 1.37 (1.43) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 19m | Losses/train_all_loss: 6.56e-01 (1.24e+00)
INFO 2025-07-01 19:02:04,016 train_utils.py: 271: Train Epoch: [31][ 50/100] | Batch Time: 1.89 (1.95) | Data Time: 1.35 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 19m | Losses/train_all_loss: 5.20e-01 (1.15e+00)
INFO 2025-07-01 19:02:23,502 train_utils.py: 271: Train Epoch: [31][ 60/100] | Batch Time: 1.80 (1.95) | Data Time: 1.27 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 20m | Losses/train_all_loss: 8.25e-01 (1.30e+00)
INFO 2025-07-01 19:02:42,617 train_utils.py: 271: Train Epoch: [31][ 70/100] | Batch Time: 1.96 (1.95) | Data Time: 1.41 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 20m | Losses/train_all_loss: 1.01e+00 (1.26e+00)
INFO 2025-07-01 19:03:01,480 train_utils.py: 271: Train Epoch: [31][ 80/100] | Batch Time: 1.78 (1.94) | Data Time: 1.24 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 20m | Losses/train_all_loss: 4.28e-01 (1.34e+00)
INFO 2025-07-01 19:03:20,528 train_utils.py: 271: Train Epoch: [31][ 90/100] | Batch Time: 1.96 (1.93) | Data Time: 1.43 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 20m | Losses/train_all_loss: 1.12e+00 (1.35e+00)
INFO 2025-07-01 19:03:37,692 trainer.py: 950: Estimated time remaining: 00d 00h 25m
INFO 2025-07-01 19:03:37,693 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 19:03:37,693 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.3760159572958945, 'Losses/train_all_loss_mask': 0.014469041548436508, 'Losses/train_all_loss_dice': 0.6396401438117028, 'Losses/train_all_loss_iou': 0.44699498888105155, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 1.3760159572958945, 'Trainer/where': 0.79975, 'Trainer/epoch': 31, 'Trainer/steps_train': 3200}
INFO 2025-07-01 19:03:40,333 train_utils.py: 271: Train Epoch: [32][  0/100] | Batch Time: 1.82 (1.82) | Data Time: 1.28 (1.28) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 21m | Losses/train_all_loss: 3.15e+00 (3.15e+00)
INFO 2025-07-01 19:04:00,232 train_utils.py: 271: Train Epoch: [32][ 10/100] | Batch Time: 2.03 (1.97) | Data Time: 1.49 (1.44) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 21m | Losses/train_all_loss: 8.78e-01 (1.21e+00)
INFO 2025-07-01 19:04:20,160 train_utils.py: 271: Train Epoch: [32][ 20/100] | Batch Time: 1.88 (1.98) | Data Time: 1.35 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 21m | Losses/train_all_loss: 3.08e+00 (1.24e+00)
INFO 2025-07-01 19:04:39,134 train_utils.py: 271: Train Epoch: [32][ 30/100] | Batch Time: 2.12 (1.96) | Data Time: 1.59 (1.43) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 22m | Losses/train_all_loss: 9.50e-01 (1.33e+00)
INFO 2025-07-01 19:04:58,712 train_utils.py: 271: Train Epoch: [32][ 40/100] | Batch Time: 2.02 (1.96) | Data Time: 1.49 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 22m | Losses/train_all_loss: 1.07e+00 (1.31e+00)
INFO 2025-07-01 19:05:18,818 train_utils.py: 271: Train Epoch: [32][ 50/100] | Batch Time: 1.81 (1.97) | Data Time: 1.30 (1.44) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 22m | Losses/train_all_loss: 3.95e+00 (1.45e+00)
INFO 2025-07-01 19:05:39,960 train_utils.py: 271: Train Epoch: [32][ 60/100] | Batch Time: 2.12 (1.99) | Data Time: 1.60 (1.46) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 23m | Losses/train_all_loss: 2.61e-01 (1.38e+00)
INFO 2025-07-01 19:06:00,998 train_utils.py: 271: Train Epoch: [32][ 70/100] | Batch Time: 1.96 (2.01) | Data Time: 1.42 (1.47) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 23m | Losses/train_all_loss: 5.44e-01 (1.37e+00)
INFO 2025-07-01 19:06:20,324 train_utils.py: 271: Train Epoch: [32][ 80/100] | Batch Time: 1.74 (2.00) | Data Time: 1.21 (1.47) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 23m | Losses/train_all_loss: 1.70e+00 (1.39e+00)
INFO 2025-07-01 19:06:40,014 train_utils.py: 271: Train Epoch: [32][ 90/100] | Batch Time: 2.09 (1.99) | Data Time: 1.57 (1.46) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 24m | Losses/train_all_loss: 3.85e-01 (1.35e+00)
INFO 2025-07-01 19:06:57,544 trainer.py: 950: Estimated time remaining: 00d 00h 23m
INFO 2025-07-01 19:06:57,545 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 19:06:57,545 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.347618044167757, 'Losses/train_all_loss_mask': 0.014730786787113174, 'Losses/train_all_loss_dice': 0.6405662356317043, 'Losses/train_all_loss_iou': 0.4124360689893365, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 1.347618044167757, 'Trainer/where': 0.8247500000000001, 'Trainer/epoch': 32, 'Trainer/steps_train': 3300}
INFO 2025-07-01 19:07:00,238 train_utils.py: 271: Train Epoch: [33][  0/100] | Batch Time: 1.94 (1.94) | Data Time: 1.39 (1.39) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 24m | Losses/train_all_loss: 1.09e+00 (1.09e+00)
INFO 2025-07-01 19:07:20,542 train_utils.py: 271: Train Epoch: [33][ 10/100] | Batch Time: 2.04 (2.02) | Data Time: 1.51 (1.50) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 24m | Losses/train_all_loss: 1.96e+00 (1.86e+00)
INFO 2025-07-01 19:07:40,291 train_utils.py: 271: Train Epoch: [33][ 20/100] | Batch Time: 2.24 (2.00) | Data Time: 1.71 (1.47) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 25m | Losses/train_all_loss: 9.05e-01 (1.91e+00)
INFO 2025-07-01 19:07:59,477 train_utils.py: 271: Train Epoch: [33][ 30/100] | Batch Time: 2.11 (1.97) | Data Time: 1.59 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 25m | Losses/train_all_loss: 2.45e+00 (1.73e+00)
INFO 2025-07-01 19:08:19,085 train_utils.py: 271: Train Epoch: [33][ 40/100] | Batch Time: 1.85 (1.97) | Data Time: 1.33 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 25m | Losses/train_all_loss: 3.66e-01 (1.59e+00)
INFO 2025-07-01 19:08:39,042 train_utils.py: 271: Train Epoch: [33][ 50/100] | Batch Time: 2.06 (1.98) | Data Time: 1.54 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 26m | Losses/train_all_loss: 8.04e-01 (1.48e+00)
INFO 2025-07-01 19:08:58,495 train_utils.py: 271: Train Epoch: [33][ 60/100] | Batch Time: 1.80 (1.97) | Data Time: 1.41 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 26m | Losses/train_all_loss: 1.49e+00 (1.53e+00)
INFO 2025-07-01 19:09:14,974 train_utils.py: 271: Train Epoch: [33][ 70/100] | Batch Time: 1.63 (1.93) | Data Time: 1.24 (1.43) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 26m | Losses/train_all_loss: 6.08e-01 (1.62e+00)
INFO 2025-07-01 19:09:32,434 train_utils.py: 271: Train Epoch: [33][ 80/100] | Batch Time: 1.76 (1.90) | Data Time: 1.38 (1.42) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 27m | Losses/train_all_loss: 1.67e+00 (1.57e+00)
INFO 2025-07-01 19:09:49,609 train_utils.py: 271: Train Epoch: [33][ 90/100] | Batch Time: 1.87 (1.88) | Data Time: 1.48 (1.41) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 27m | Losses/train_all_loss: 1.24e+00 (1.59e+00)
INFO 2025-07-01 19:10:05,045 trainer.py: 950: Estimated time remaining: 00d 00h 18m
INFO 2025-07-01 19:10:05,046 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 19:10:05,046 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.5886796337366105, 'Losses/train_all_loss_mask': 0.01945017878198996, 'Losses/train_all_loss_dice': 0.7029563836753369, 'Losses/train_all_loss_iou': 0.4967196701467037, 'Losses/train_all_loss_class': 1.1126199410682603e-08, 'Losses/train_all_core_loss': 1.5886796337366105, 'Trainer/where': 0.84975, 'Trainer/epoch': 33, 'Trainer/steps_train': 3400}
INFO 2025-07-01 19:10:07,340 train_utils.py: 271: Train Epoch: [34][  0/100] | Batch Time: 1.54 (1.54) | Data Time: 1.12 (1.12) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 27m | Losses/train_all_loss: 1.36e+00 (1.36e+00)
INFO 2025-07-01 19:10:24,684 train_utils.py: 271: Train Epoch: [34][ 10/100] | Batch Time: 1.59 (1.72) | Data Time: 1.20 (1.33) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 28m | Losses/train_all_loss: 6.14e-01 (1.16e+00)
INFO 2025-07-01 19:10:42,373 train_utils.py: 271: Train Epoch: [34][ 20/100] | Batch Time: 1.81 (1.74) | Data Time: 1.43 (1.35) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 28m | Losses/train_all_loss: 9.94e-01 (1.35e+00)
INFO 2025-07-01 19:11:00,375 train_utils.py: 271: Train Epoch: [34][ 30/100] | Batch Time: 1.84 (1.76) | Data Time: 1.45 (1.37) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 28m | Losses/train_all_loss: 6.37e-01 (1.34e+00)
INFO 2025-07-01 19:11:17,609 train_utils.py: 271: Train Epoch: [34][ 40/100] | Batch Time: 1.70 (1.75) | Data Time: 1.32 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 28m | Losses/train_all_loss: 1.40e+00 (1.30e+00)
INFO 2025-07-01 19:11:35,018 train_utils.py: 271: Train Epoch: [34][ 50/100] | Batch Time: 1.59 (1.75) | Data Time: 1.20 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 29m | Losses/train_all_loss: 2.76e+00 (1.27e+00)
INFO 2025-07-01 19:11:52,854 train_utils.py: 271: Train Epoch: [34][ 60/100] | Batch Time: 1.83 (1.76) | Data Time: 1.44 (1.37) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 29m | Losses/train_all_loss: 9.58e-01 (1.25e+00)
INFO 2025-07-01 19:12:10,077 train_utils.py: 271: Train Epoch: [34][ 70/100] | Batch Time: 1.76 (1.75) | Data Time: 1.38 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 29m | Losses/train_all_loss: 2.20e+00 (1.33e+00)
INFO 2025-07-01 19:12:27,418 train_utils.py: 271: Train Epoch: [34][ 80/100] | Batch Time: 1.78 (1.75) | Data Time: 1.39 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 30m | Losses/train_all_loss: 5.92e-01 (1.37e+00)
INFO 2025-07-01 19:12:45,155 train_utils.py: 271: Train Epoch: [34][ 90/100] | Batch Time: 1.78 (1.75) | Data Time: 1.38 (1.36) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 30m | Losses/train_all_loss: 4.24e-01 (1.42e+00)
INFO 2025-07-01 19:13:02,288 trainer.py: 950: Estimated time remaining: 00d 00h 14m
INFO 2025-07-01 19:13:02,289 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 19:13:02,289 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.4572209778428078, 'Losses/train_all_loss_mask': 0.0165846760495333, 'Losses/train_all_loss_dice': 0.6608065465092658, 'Losses/train_all_loss_iou': 0.4647208944708109, 'Losses/train_all_loss_class': 1.8676112176763127e-08, 'Losses/train_all_core_loss': 1.4572209778428078, 'Trainer/where': 0.87475, 'Trainer/epoch': 34, 'Trainer/steps_train': 3500}
INFO 2025-07-01 19:13:05,038 train_utils.py: 271: Train Epoch: [35][  0/100] | Batch Time: 1.93 (1.93) | Data Time: 1.51 (1.51) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 30m | Losses/train_all_loss: 7.33e-01 (7.33e-01)
INFO 2025-07-01 19:13:23,869 train_utils.py: 271: Train Epoch: [35][ 10/100] | Batch Time: 1.84 (1.89) | Data Time: 1.46 (1.49) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 31m | Losses/train_all_loss: 5.74e-01 (9.88e-01)
INFO 2025-07-01 19:13:42,537 train_utils.py: 271: Train Epoch: [35][ 20/100] | Batch Time: 1.76 (1.88) | Data Time: 1.38 (1.49) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 31m | Losses/train_all_loss: 1.84e+00 (1.15e+00)
INFO 2025-07-01 19:14:00,189 train_utils.py: 271: Train Epoch: [35][ 30/100] | Batch Time: 1.95 (1.84) | Data Time: 1.52 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 31m | Losses/train_all_loss: 1.34e+00 (1.11e+00)
INFO 2025-07-01 19:14:18,750 train_utils.py: 271: Train Epoch: [35][ 40/100] | Batch Time: 1.60 (1.84) | Data Time: 1.20 (1.44) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 31m | Losses/train_all_loss: 7.58e-01 (1.27e+00)
INFO 2025-07-01 19:14:37,712 train_utils.py: 271: Train Epoch: [35][ 50/100] | Batch Time: 1.78 (1.85) | Data Time: 1.37 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 32m | Losses/train_all_loss: 8.39e-01 (1.32e+00)
INFO 2025-07-01 19:14:56,795 train_utils.py: 271: Train Epoch: [35][ 60/100] | Batch Time: 2.01 (1.86) | Data Time: 1.62 (1.46) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 32m | Losses/train_all_loss: 1.07e+00 (1.35e+00)
WARNING 2025-07-01 19:15:11,664 transforms.py: 349: Skip RandomAffine for zero-area mask in first frame after 1 tentatives
INFO 2025-07-01 19:15:16,318 train_utils.py: 271: Train Epoch: [35][ 70/100] | Batch Time: 2.09 (1.88) | Data Time: 1.70 (1.47) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 32m | Losses/train_all_loss: 1.40e+00 (1.30e+00)
INFO 2025-07-01 19:15:36,854 train_utils.py: 271: Train Epoch: [35][ 80/100] | Batch Time: 2.29 (1.90) | Data Time: 1.86 (1.49) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 33m | Losses/train_all_loss: 6.30e-01 (1.27e+00)
INFO 2025-07-01 19:15:56,731 train_utils.py: 271: Train Epoch: [35][ 90/100] | Batch Time: 2.01 (1.91) | Data Time: 1.61 (1.50) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 33m | Losses/train_all_loss: 7.32e-01 (1.25e+00)
INFO 2025-07-01 19:16:14,219 trainer.py: 950: Estimated time remaining: 00d 00h 12m
INFO 2025-07-01 19:16:14,219 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 19:16:14,219 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.2265851700305939, 'Losses/train_all_loss_mask': 0.014548305179341697, 'Losses/train_all_loss_dice': 0.5676878764480352, 'Losses/train_all_loss_iou': 0.3679311863332987, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 1.2265851700305939, 'Trainer/where': 0.89975, 'Trainer/epoch': 35, 'Trainer/steps_train': 3600}
INFO 2025-07-01 19:16:16,946 train_utils.py: 271: Train Epoch: [36][  0/100] | Batch Time: 1.88 (1.88) | Data Time: 1.45 (1.45) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 33m | Losses/train_all_loss: 7.90e-01 (7.90e-01)
INFO 2025-07-01 19:16:38,256 train_utils.py: 271: Train Epoch: [36][ 10/100] | Batch Time: 2.07 (2.11) | Data Time: 1.66 (1.66) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 34m | Losses/train_all_loss: 7.94e-01 (9.04e-01)
INFO 2025-07-01 19:16:58,588 train_utils.py: 271: Train Epoch: [36][ 20/100] | Batch Time: 2.41 (2.07) | Data Time: 1.96 (1.64) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 34m | Losses/train_all_loss: 3.60e+00 (9.58e-01)
INFO 2025-07-01 19:17:18,574 train_utils.py: 271: Train Epoch: [36][ 30/100] | Batch Time: 2.00 (2.05) | Data Time: 1.58 (1.62) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 34m | Losses/train_all_loss: 2.65e-01 (9.73e-01)
INFO 2025-07-01 19:17:43,456 train_utils.py: 271: Train Epoch: [36][ 40/100] | Batch Time: 2.20 (2.16) | Data Time: 1.77 (1.71) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 35m | Losses/train_all_loss: 8.15e-01 (1.03e+00)
INFO 2025-07-01 19:18:02,730 train_utils.py: 271: Train Epoch: [36][ 50/100] | Batch Time: 2.17 (2.11) | Data Time: 1.76 (1.67) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 35m | Losses/train_all_loss: 5.61e+00 (1.35e+00)
INFO 2025-07-01 19:18:24,092 train_utils.py: 271: Train Epoch: [36][ 60/100] | Batch Time: 2.37 (2.12) | Data Time: 1.92 (1.67) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 36m | Losses/train_all_loss: 1.00e+00 (1.34e+00)
INFO 2025-07-01 19:18:45,009 train_utils.py: 271: Train Epoch: [36][ 70/100] | Batch Time: 2.42 (2.11) | Data Time: 1.97 (1.67) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 36m | Losses/train_all_loss: 8.37e-01 (1.34e+00)
INFO 2025-07-01 19:19:04,486 train_utils.py: 271: Train Epoch: [36][ 80/100] | Batch Time: 1.94 (2.09) | Data Time: 1.53 (1.65) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 36m | Losses/train_all_loss: 6.56e-01 (1.54e+00)
INFO 2025-07-01 19:19:25,861 train_utils.py: 271: Train Epoch: [36][ 90/100] | Batch Time: 1.81 (2.10) | Data Time: 1.40 (1.64) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 37m | Losses/train_all_loss: 1.29e+00 (1.49e+00)
INFO 2025-07-01 19:19:44,072 trainer.py: 950: Estimated time remaining: 00d 00h 10m
INFO 2025-07-01 19:19:44,074 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 19:19:44,075 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.452742362767458, 'Losses/train_all_loss_mask': 0.019718832162907346, 'Losses/train_all_loss_dice': 0.6280920418351889, 'Losses/train_all_loss_iou': 0.4302736692875624, 'Losses/train_all_loss_class': 0.0, 'Losses/train_all_core_loss': 1.452742362767458, 'Trainer/where': 0.9247500000000001, 'Trainer/epoch': 36, 'Trainer/steps_train': 3700}
INFO 2025-07-01 19:19:49,566 train_utils.py: 271: Train Epoch: [37][  0/100] | Batch Time: 4.35 (4.35) | Data Time: 3.72 (3.72) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 37m | Losses/train_all_loss: 4.65e+00 (4.65e+00)
INFO 2025-07-01 19:20:09,414 train_utils.py: 271: Train Epoch: [37][ 10/100] | Batch Time: 1.92 (2.20) | Data Time: 1.53 (1.76) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 37m | Losses/train_all_loss: 2.29e+00 (1.48e+00)
INFO 2025-07-01 19:20:29,515 train_utils.py: 271: Train Epoch: [37][ 20/100] | Batch Time: 1.87 (2.11) | Data Time: 1.46 (1.68) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 38m | Losses/train_all_loss: 5.10e-01 (1.71e+00)
INFO 2025-07-01 19:20:51,289 train_utils.py: 271: Train Epoch: [37][ 30/100] | Batch Time: 2.14 (2.13) | Data Time: 1.73 (1.68) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 38m | Losses/train_all_loss: 6.85e-01 (1.53e+00)
INFO 2025-07-01 19:21:11,511 train_utils.py: 271: Train Epoch: [37][ 40/100] | Batch Time: 2.03 (2.10) | Data Time: 1.60 (1.66) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 38m | Losses/train_all_loss: 3.59e+00 (1.43e+00)
INFO 2025-07-01 19:21:32,635 train_utils.py: 271: Train Epoch: [37][ 50/100] | Batch Time: 1.94 (2.11) | Data Time: 1.45 (1.65) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 39m | Losses/train_all_loss: 1.35e+00 (1.58e+00)
INFO 2025-07-01 19:21:52,868 train_utils.py: 271: Train Epoch: [37][ 60/100] | Batch Time: 2.14 (2.09) | Data Time: 1.74 (1.64) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 39m | Losses/train_all_loss: 2.83e+00 (1.51e+00)
INFO 2025-07-01 19:22:12,520 train_utils.py: 271: Train Epoch: [37][ 70/100] | Batch Time: 1.97 (2.07) | Data Time: 1.57 (1.63) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 39m | Losses/train_all_loss: 7.03e+00 (1.63e+00)
INFO 2025-07-01 19:22:34,217 train_utils.py: 271: Train Epoch: [37][ 80/100] | Batch Time: 1.93 (2.09) | Data Time: 1.53 (1.64) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 40m | Losses/train_all_loss: 1.49e+00 (1.63e+00)
INFO 2025-07-01 19:22:53,395 train_utils.py: 271: Train Epoch: [37][ 90/100] | Batch Time: 1.96 (2.07) | Data Time: 1.54 (1.63) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 40m | Losses/train_all_loss: 1.04e+00 (1.53e+00)
INFO 2025-07-01 19:23:11,342 trainer.py: 950: Estimated time remaining: 00d 00h 06m
INFO 2025-07-01 19:23:11,343 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 19:23:11,343 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.5029296240210532, 'Losses/train_all_loss_mask': 0.02030259203806054, 'Losses/train_all_loss_dice': 0.6407703813165426, 'Losses/train_all_loss_iou': 0.45610740207135675, 'Losses/train_all_loss_class': 3.9736427481784633e-10, 'Losses/train_all_core_loss': 1.5029296240210532, 'Trainer/where': 0.9497500000000001, 'Trainer/epoch': 37, 'Trainer/steps_train': 3800}
INFO 2025-07-01 19:23:14,128 train_utils.py: 271: Train Epoch: [38][  0/100] | Batch Time: 1.90 (1.90) | Data Time: 1.43 (1.43) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 40m | Losses/train_all_loss: 1.14e+00 (1.14e+00)
INFO 2025-07-01 19:23:33,592 train_utils.py: 271: Train Epoch: [38][ 10/100] | Batch Time: 1.89 (1.94) | Data Time: 1.48 (1.53) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 41m | Losses/train_all_loss: 2.44e+00 (1.05e+00)
INFO 2025-07-01 19:23:54,059 train_utils.py: 271: Train Epoch: [38][ 20/100] | Batch Time: 1.70 (1.99) | Data Time: 1.28 (1.54) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 41m | Losses/train_all_loss: 5.84e-01 (1.18e+00)
INFO 2025-07-01 19:24:13,705 train_utils.py: 271: Train Epoch: [38][ 30/100] | Batch Time: 1.85 (1.98) | Data Time: 1.43 (1.54) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 41m | Losses/train_all_loss: 2.39e-01 (1.06e+00)
INFO 2025-07-01 19:24:33,223 train_utils.py: 271: Train Epoch: [38][ 40/100] | Batch Time: 2.20 (1.98) | Data Time: 1.68 (1.53) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 42m | Losses/train_all_loss: 1.98e+00 (1.07e+00)
INFO 2025-07-01 19:24:55,977 train_utils.py: 271: Train Epoch: [38][ 50/100] | Batch Time: 2.11 (2.03) | Data Time: 1.64 (1.59) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 42m | Losses/train_all_loss: 5.22e-01 (1.20e+00)
INFO 2025-07-01 19:25:18,564 train_utils.py: 271: Train Epoch: [38][ 60/100] | Batch Time: 4.18 (2.07) | Data Time: 2.46 (1.61) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 42m | Losses/train_all_loss: 7.90e-01 (1.16e+00)
INFO 2025-07-01 19:25:38,347 train_utils.py: 271: Train Epoch: [38][ 70/100] | Batch Time: 2.04 (2.06) | Data Time: 1.64 (1.60) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 43m | Losses/train_all_loss: 2.33e+00 (1.22e+00)
INFO 2025-07-01 19:25:57,755 train_utils.py: 271: Train Epoch: [38][ 80/100] | Batch Time: 1.90 (2.04) | Data Time: 1.48 (1.59) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 43m | Losses/train_all_loss: 6.66e-01 (1.19e+00)
INFO 2025-07-01 19:26:19,679 train_utils.py: 271: Train Epoch: [38][ 90/100] | Batch Time: 2.07 (2.06) | Data Time: 1.66 (1.61) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 43m | Losses/train_all_loss: 9.09e-01 (1.17e+00)
INFO 2025-07-01 19:26:37,263 trainer.py: 950: Estimated time remaining: 00d 00h 03m
INFO 2025-07-01 19:26:37,263 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 19:26:37,263 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.1215889176726341, 'Losses/train_all_loss_mask': 0.012788934060372412, 'Losses/train_all_loss_dice': 0.529715745896101, 'Losses/train_all_loss_iou': 0.3360943534970284, 'Losses/train_all_loss_class': 1.4344707935265433e-07, 'Losses/train_all_core_loss': 1.1215889176726341, 'Trainer/where': 0.97475, 'Trainer/epoch': 38, 'Trainer/steps_train': 3900}
INFO 2025-07-01 19:26:40,024 train_utils.py: 271: Train Epoch: [39][  0/100] | Batch Time: 1.85 (1.85) | Data Time: 1.40 (1.40) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 44m | Losses/train_all_loss: 2.26e+00 (2.26e+00)
INFO 2025-07-01 19:26:59,642 train_utils.py: 271: Train Epoch: [39][ 10/100] | Batch Time: 2.00 (1.95) | Data Time: 1.59 (1.53) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 44m | Losses/train_all_loss: 1.28e+00 (1.19e+00)
INFO 2025-07-01 19:27:19,313 train_utils.py: 271: Train Epoch: [39][ 20/100] | Batch Time: 3.35 (1.96) | Data Time: 2.18 (1.51) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 44m | Losses/train_all_loss: 8.02e-01 (1.30e+00)
INFO 2025-07-01 19:27:39,772 train_utils.py: 271: Train Epoch: [39][ 30/100] | Batch Time: 1.82 (1.99) | Data Time: 1.43 (1.54) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 45m | Losses/train_all_loss: 1.36e+00 (2.05e+00)
INFO 2025-07-01 19:27:59,197 train_utils.py: 271: Train Epoch: [39][ 40/100] | Batch Time: 1.86 (1.98) | Data Time: 1.41 (1.53) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 45m | Losses/train_all_loss: 7.57e-01 (1.77e+00)
INFO 2025-07-01 19:28:21,932 train_utils.py: 271: Train Epoch: [39][ 50/100] | Batch Time: 2.25 (2.03) | Data Time: 1.81 (1.59) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 46m | Losses/train_all_loss: 7.90e-01 (1.58e+00)
INFO 2025-07-01 19:28:42,674 train_utils.py: 271: Train Epoch: [39][ 60/100] | Batch Time: 2.01 (2.04) | Data Time: 1.59 (1.60) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 46m | Losses/train_all_loss: 1.82e-01 (1.61e+00)
WARNING 2025-07-01 19:28:56,060 transforms.py: 349: Skip RandomAffine for zero-area mask in first frame after 1 tentatives
INFO 2025-07-01 19:29:02,430 train_utils.py: 271: Train Epoch: [39][ 70/100] | Batch Time: 1.86 (2.03) | Data Time: 1.45 (1.59) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 46m | Losses/train_all_loss: 3.13e+00 (1.56e+00)
INFO 2025-07-01 19:29:24,276 train_utils.py: 271: Train Epoch: [39][ 80/100] | Batch Time: 1.70 (2.05) | Data Time: 1.30 (1.60) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 47m | Losses/train_all_loss: 7.49e-01 (1.51e+00)
INFO 2025-07-01 19:29:45,777 train_utils.py: 271: Train Epoch: [39][ 90/100] | Batch Time: 2.19 (2.06) | Data Time: 1.77 (1.61) | Mem (GB): 4.00 (4.00/4.00) | Time Elapsed: 00d 01h 47m | Losses/train_all_loss: 9.33e-01 (1.63e+00)
INFO 2025-07-01 19:30:03,730 trainer.py: 950: Estimated time remaining: 00d 00h 00m
INFO 2025-07-01 19:30:03,730 trainer.py: 892: Synchronizing meters
INFO 2025-07-01 19:30:03,731 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.5849570162594318, 'Losses/train_all_loss_mask': 0.022742101745679973, 'Losses/train_all_loss_dice': 0.6584552823007107, 'Losses/train_all_loss_iou': 0.47165967946872117, 'Losses/train_all_loss_class': 2.58286671339647e-08, 'Losses/train_all_core_loss': 1.5849570162594318, 'Trainer/where': 0.99975, 'Trainer/epoch': 39, 'Trainer/steps_train': 4000}
